{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip\n","!unzip ml-1m.zip"],"metadata":{"id":"O07YlyIB9ZW3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671642627924,"user_tz":-480,"elapsed":1224,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"e665a68d-4650-4030-f9a9-a57865b6115c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-21 17:10:25--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5917549 (5.6M) [application/zip]\n","Saving to: ‘ml-1m.zip’\n","\n","ml-1m.zip           100%[===================>]   5.64M  6.90MB/s    in 0.8s    \n","\n","2022-12-21 17:10:27 (6.90 MB/s) - ‘ml-1m.zip’ saved [5917549/5917549]\n","\n","Archive:  ml-1m.zip\n","   creating: ml-1m/\n","  inflating: ml-1m/movies.dat        \n","  inflating: ml-1m/ratings.dat       \n","  inflating: ml-1m/README            \n","  inflating: ml-1m/users.dat         \n"]}]},{"cell_type":"code","source":["import torch\n","try:\n","    import torch_geometric\n","except ModuleNotFoundError:\n","    TORCH = torch.__version__.split(\"+\")[0]\n","    CUDA = \"cu\" + torch.version.cuda.replace(\".\", \"\")\n","!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n","!pip install torch-geometric"],"metadata":{"id":"BKI0b5Y5wMIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import math\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch_geometric.data import Dataset, Data\n","from torch_geometric.typing import Adj\n","from torch_geometric.nn import MessagePassing\n","from tqdm import tqdm\n","import collections"],"metadata":{"id":"uH-CvYabpwds"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1) LightGCN\n","\n","GNN is a general name for a set of models that considers the problem setup from a graph perspective and utilizes neural networks to make predictions. In GNN, entities are usually treated as nodes, and relationships between entities are described by edges. One could further supplement the graph with additional information by attaching node features and edge features to the graph. GNN generates embeddings while taking into account graph structures. \n","\n","Among all instances of GNN, LightGCN is one that delivers state-of-the-art empirical performance on benchmarks for recommendations\n","\n","https://medium.com/stanford-cs224w/lightgcn-for-movie-recommendation-eb6d112f1e8\n","\n","https://colab.research.google.com/drive/1VfP6JlWbX_AJnx88yN1tM3BYE6XAADiy?usp=sharing#scrollTo=G30yzPzf6A36"],"metadata":{"id":"XTJt8zzRoHRf"}},{"cell_type":"markdown","source":["## 1.1 Data Loading"],"metadata":{"id":"FKnKr7PVoFpV"}},{"cell_type":"code","source":["unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n","users = pd.read_table(\n","    './ml-1m/users.dat', sep='::', header=None, names=unames, engine='python', encoding='latin-1')\n","\n","rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n","ratings = pd.read_table(\n","    './ml-1m/ratings.dat', sep='::', header=None, names=rnames, engine='python', encoding='latin-1')\n","\n","mnames = ['movie_id', 'title', 'genres']\n","movies = pd.read_table(\n","    './ml-1m/movies.dat', sep='::', header=None, names=mnames, engine='python', encoding='latin-1')\n","\n","df_full = pd.merge(pd.merge(ratings, users), movies)\n","matrix_data = df_full.groupby(['user_id', 'movie_id'])['rating'].mean().unstack().fillna(0)\n","matrix_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"6tNl_G1omwPH","executionInfo":{"status":"ok","timestamp":1671642657679,"user_tz":-480,"elapsed":6860,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"c6bf166a-a79c-4959-f90f-d475102dece2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n","user_id                                                               ...   \n","1          5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","5          0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0   0.0  ...   \n","\n","movie_id  3943  3944  3945  3946  3947  3948  3949  3950  3951  3952  \n","user_id                                                               \n","1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","\n","[5 rows x 3706 columns]"],"text/html":["\n","  <div id=\"df-802f20ab-7af5-48da-9436-5aa1ce30656a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>movie_id</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>...</th>\n","      <th>3943</th>\n","      <th>3944</th>\n","      <th>3945</th>\n","      <th>3946</th>\n","      <th>3947</th>\n","      <th>3948</th>\n","      <th>3949</th>\n","      <th>3950</th>\n","      <th>3951</th>\n","      <th>3952</th>\n","    </tr>\n","    <tr>\n","      <th>user_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 3706 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-802f20ab-7af5-48da-9436-5aa1ce30656a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-802f20ab-7af5-48da-9436-5aa1ce30656a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-802f20ab-7af5-48da-9436-5aa1ce30656a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["rating_threshold = 3\n","config_dict = {\n","    \"num_samples_per_user\": 100,\n","    \"num_users\": 200,\n","\n","    \"epochs\": 100,\n","    \"batch_size\": 128,\n","    \"lr\": 0.001,\n","    \"weight_decay\": 0.1,\n","\n","    \"embedding_size\": 64,\n","    \"num_layers\": 5,\n","    \"K\": 10,\n","    \"mf_rank\": 8,\n","\n","    \"minibatch_per_print\": 100,\n","    \"epochs_per_print\": 1,\n","\n","    \"val_frac\": 0.2,\n","    \"test_frac\": 0.1,\n","\n","    \"model_name\": \"model.pth\"\n","}\n","\n","epochs = config_dict[\"epochs\"]\n","batch_size = config_dict[\"batch_size\"]\n","lr = config_dict[\"lr\"]\n","weight_decay = config_dict[\"weight_decay\"]\n","K = config_dict[\"K\"]"],"metadata":{"id":"DHT3z7DdhPzG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def trans_ml(dat, thres):\n","    \"\"\"\n","    Transform function that assign non-negative entries >= thres 1, and non-\n","    negative entries <= thres 0. Keep other entries the same.\n","    \"\"\"\n","    thres = thres[0]\n","    matrix = dat['edge_index']\n","    matrix[(matrix < thres) & (matrix > -1)] = 0\n","    matrix[(matrix >= thres)] = 1\n","    dat['edge_index'] = matrix\n","    return dat\n","\n","class MovieLens(Dataset):\n","    def __init__(self, data, config):\n","        super(MovieLens, self).__init__()\n","        self.data = data\n","        self.config = config\n","\n","    def train_val_test_split(self, val_frac=0.2, test_frac=0.1):\n","        \"\"\"\n","        Return two mask matrices (M, N) that represents edges present in the\n","        train and validation set\n","        \"\"\"\n","    \n","        try:\n","            self.num_user, self.num_item\n","        except AttributeError:\n","            self.num_user = len(self.data[\"users\"].unique())\n","            self.num_item = len(self.data[\"items\"].unique())\n","\n","        # get number of edges masked for training and validation\n","        num_train_replaced = round((test_frac + val_frac) * self.num_user * self.num_item)\n","        num_val_show = round(val_frac * self.num_user * self.num_item)\n","\n","        # edges masked during training\n","        # list of int\n","        indices_user = np.random.randint(0, self.num_user, num_train_replaced)\n","        indices_item = np.random.randint(0, self.num_item, num_train_replaced)\n","        \n","        # sample part of edges from training stage to be unmasked during validation\n","        # list of int\n","        indices_val_user = np.random.choice(indices_user, num_val_show)\n","        indices_val_item = np.random.choice(indices_item, num_val_show)\n","\n","        train_mask = torch.ones(self.num_user, self.num_item)\n","        train_mask[indices_user, indices_item] = 0\n","\n","        val_mask = train_mask.clone()\n","        val_mask[indices_val_user, indices_val_item] = 1\n","        test_mask = torch.ones_like(train_mask)\n","\n","        return train_mask, val_mask, test_mask\n","\n","    def _sample_pos_neg(self, data, mask, num_samples_per_user):\n","        \"\"\"\n","        Samples (user, positive item, negative item) tuples per user.\n","        If a user does not have a postive (negative) item, we choose an item\n","        with unknown liking (an item without raw rating data).\n","\n","        Args:\n","            data: Dataset object containing edge_index and raw ratings matrix.\n","            mask: Masking matrix indicating edges present in the current set\n","            num_samples_per_user: Number of samples to generate for each user.\n","\n","        Returns:\n","            torch.Tensor object of (user, positive item, negative item) samples.\n","        \"\"\"\n","\n","        samples = []\n","        all_items = set(range(len(data[\"items\"])))\n","\n","        for user_index, user in enumerate(data[\"users\"]):\n","            \n","            # empty set\n","            pos_items = set(\n","                torch.nonzero(data[\"edge_index\"][user_index])[:, 0].tolist())\n","            \n","            # all item\n","            unknown_items = all_items.difference(\n","                    set(torch.nonzero(data[\"raw_edge_index\"][user_index])[:, 0].tolist()))\n","\n","            # empty set   \n","            neg_items = all_items.difference(\n","                set(pos_items)).difference(set(unknown_items))\n","\n","            # all item without mask\n","            unmasked_items = set(torch.nonzero(mask[user_index])[:, 0].tolist())\n","\n","            if (len(unknown_items.union(pos_items)) == 0) or (len(unknown_items.union(neg_items)) == 0):\n","                continue\n","                                                                                                                                                   \n","            for _ in range(num_samples_per_user):\n","\n","                if len(pos_items.intersection(unmasked_items)) == 0:\n","                    pos_item_index = random.choice(list(unknown_items.intersection(unmasked_items)))\n","                else:\n","                    pos_item_index = random.choice(list(pos_items.intersection(unmasked_items)))\n","                    \n","                if len(neg_items.intersection(unmasked_items)) == 0:\n","                    neg_item_index = random.choice(list(unknown_items.intersection(unmasked_items)))\n","                else:\n","                    neg_item_index = random.choice(list(neg_items.intersection(unmasked_items)))\n","                    \n","                samples.append((user_index, pos_item_index, neg_item_index))\n","\n","        return torch.tensor(samples, dtype=torch.int32)\n","\n","    def sample_pos_neg(self):\n","        \"\"\"\n","        Args:\n","            data: Dataset object containing edge_index and raw ratings matrix.\n","            train_mask: Masking matrix indicating edges present in train set.\n","            val_mask: Masking matrix indicating edges present in validation set.\n","            test_mask: Masking matrix indicating edges present in test set.\n","            num_samples_per_user: Number of samples to generate for each user.\n","\n","        Returns:\n","            torch.Tensor object of (user, positive item, negative item) samples for\n","            train, validation and test.\n","        \"\"\"\n","\n","        config = self.config\n","        train_mask, val_mask, test_mask = self.train_val_test_split(\n","            config['val_frac'], config['test_frac']\n","        )\n","\n","        train_samples = self._sample_pos_neg(self.data, train_mask, config['num_samples_per_user'])\n","        val_samples = self._sample_pos_neg(self.data, val_mask, config['num_samples_per_user'])\n","        test_samples = self._sample_pos_neg(self.data, test_mask, config['num_samples_per_user'])\n","        return train_samples, val_samples, test_samples, train_mask, val_mask, test_mask\n","\n","# create Data object\n","data = Data(\n","    edge_index=torch.Tensor(matrix_data.to_numpy()),\n","    raw_edge_index=torch.Tensor(matrix_data.to_numpy()).clone(),\n","    data=ratings,\n","    users=users['user_id'],\n","    items=movies['movie_id'],\n","    )\n","\n","# pre-process\n","data = trans_ml(data, [rating_threshold])\n","movie_dataset = MovieLens(data, config_dict)\n","(samples_train, samples_val, samples_test, train_mask, val_mask, test_mask) = \\\n","    movie_dataset.sample_pos_neg()\n","\n","print(samples_train.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad0HbSjK99cc","executionInfo":{"status":"ok","timestamp":1671646375214,"user_tz":-480,"elapsed":5,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"8a0389d5-f06f-47fa-dbf7-ce5f0dd5b61f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([604000, 3])\n"]}]},{"cell_type":"markdown","source":["## 1.2 Implementation"],"metadata":{"id":"VaoWwVjShG_X"}},{"cell_type":"markdown","source":["### 1.2.1 LightGCN neighbourhood aggregation layer\n","\n","Starting with the initial embeddings $E^{(0)}$ and the bipartite graph, we iterate over each node to perform neighborhood aggregation. Note that LightGCN uses **a simple weighted sum aggregator** and **avoids the heavy-lifting feature transformation and nonlinear activation**.\n","\n","Within each layer, for each user in the graph, we compute its updated embedding as the weighted sum of embeddings from all its neighboring items (movies) following the formula below:\n","$$ \\textbf{e}_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|} \\sqrt{|N_i|}} \\textbf{e}_i^{(k)} $$\n","where $ \\textbf{e}_u^{(k)} $ and $ \\textbf{e}_i^{(k)} $ are the user and item (movie) node embeddings at the k-th layer. $ |N_u| $ and $ |N_i| $ are the user and item nodes’ number of neighbors.\n","\n","Similarly, for each item, the updated embedding is computed using weighted sum of its neighboring users:\n","$$ \\textbf{e}_i^{(k+1)} = \\sum_{i \\in N_i} \\frac{1}{\\sqrt{|N_i|} \\sqrt{|N_u|}} \\textbf{e}_u^{(k)} $$"],"metadata":{"id":"6cpTBGZPh5-W"}},{"cell_type":"code","source":["class LightGCNConv(MessagePassing):\n","    \"\"\"\n","    Args:\n","        in_channels (int): Size of each input sample.\n","        out_channels (int): Size of each output sample.\n","        num_users (int): Number of users for recommendation.\n","        num_items (int): Number of items to recommend.\n","        **kwargs (optional): Additional arguments of\n","            :class:`torch_geometric.nn.conv.MessagePassing`.\n","    \"\"\"\n","    def __init__(\n","        self, in_channels: int, out_channels: int,num_users: int, num_items: int, **kwargs\n","        ):\n","\n","        super(LightGCNConv, self).__init__(**kwargs)\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.num_users = num_users\n","        self.num_items = num_items\n","\n","    def forward(self, x, edge_index):\n","        \"\"\"Performs neighborhood aggregation for user/item embeddings.\"\"\"\n","\n","        user_item = torch.zeros(self.num_users, self.num_items, device=x.device)\n","        user_item[edge_index[:, 0], edge_index[:, 1]] = 1\n","        user_neighbor_counts = torch.sum(user_item, axis=1)\n","        item_neightbor_counts = torch.sum(user_item, axis=0)\n","\n","        # Compute weight for aggregation: 1 / sqrt(N_u * N_i)\n","        weights = user_item / torch.sqrt(\n","                user_neighbor_counts.repeat(self.num_items, 1).T \\\n","                * item_neightbor_counts.repeat(self.num_users, 1))\n","        \n","        weights = torch.nan_to_num(weights, nan=0)\n","        out = torch.concat(\n","            (\n","                weights.T @ x[:self.num_users],\n","             weights @ x[self.num_users:]), \n","             0)\n","        return out"],"metadata":{"id":"zAlXFkZWaeJo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2.2 LightGCN model\n","\n","At layer combination, instead of taking the embedding of the final layer, LightGCN computes **a weighted sum of the embeddings at different layers**:\n","$$ \\textbf{e}_u = \\sum_{k=0}^K \\alpha_k \\textbf{e}_u^{(k)} $$\n","$$ \\textbf{e}_i = \\sum_{k=0}^K \\alpha_k \\textbf{e}_i^{(k)} $$\n","with $ \\alpha \\ge 0 $. Here, alpha values can either be learned as network parameters, or set as empirical hyperparameters. It has been found that $ \\alpha = \\frac{1}{K + 1} $ works well.\n","\n","LightGCN predicts based on the inner product of the final user and item (movie) embeddings:\n","$$ \\hat{y}_{ui} = \\textbf{e}_u^T \\textbf{e}_i $$\n","This inner product measures the similarity between the user and movie, therefore allowing us to understand how likely it is for the user to like the movie."],"metadata":{"id":"NYh_ARlAjNf6"}},{"cell_type":"code","source":["class LightGCN(nn.Module):\n","    def __init__(\n","        self, \n","        config: dict,\n","        device=None,\n","        **kwargs):\n","\n","        super().__init__()\n","\n","        self.num_users  = config[\"n_users\"]\n","        self.num_items  = config[\"m_items\"]\n","        self.embedding_size = config[\"embedding_size\"]\n","        self.in_channels = self.embedding_size\n","        self.out_channels = self.embedding_size\n","        self.num_layers = config[\"num_layers\"]\n","\n","        # 0-th layer embedding.\n","        self.embedding_user_item = torch.nn.Embedding(\n","            num_embeddings=self.num_users + self.num_items,\n","            embedding_dim=self.embedding_size)\n","        self.alpha = None\n","\n","        # random normal init seems to be a better choice when lightGCN actually\n","        # don't use any non-linear activation function\n","        nn.init.normal_(self.embedding_user_item.weight, std=0.1)\n","        print('use NORMAL distribution initilizer')\n","\n","        self.f = nn.Sigmoid()\n","\n","        self.convs = nn.ModuleList()\n","        self.convs.append(LightGCNConv(\n","                self.embedding_size, self.embedding_size,\n","                num_users=self.num_users, num_items=self.num_items, **kwargs))\n","\n","        for _ in range(1, self.num_layers):\n","            self.convs.append(\n","                LightGCNConv(\n","                        self.embedding_size, self.embedding_size, \n","                        num_users=self.num_users, num_items=self.num_items,\n","                        **kwargs))\n","\n","        self.device = None\n","        if device is not None:\n","            self.convs.to(device)\n","            self.device = device\n","\n","    def reset_parameters(self):\n","        for conv in self.convs:\n","            conv.reset_parameters()\n","\n","    def forward(self, x, edge_index, *args, **kwargs):\n","        xs = []\n","\n","        edge_index = torch.nonzero(edge_index)\n","        for i in range(self.num_layers):\n","            x = self.convs[i](x, edge_index, *args, **kwargs)\n","            if self.device is not None:\n","                x = x.to(self.device)\n","            xs.append(x)\n","        xs = torch.stack(xs)\n","        \n","        self.alpha = 1 / (1 + self.num_layers) * torch.ones(xs.shape)\n","        if self.device is not None:\n","            self.alpha = self.alpha.to(self.device)\n","            xs = xs.to(self.device)\n","        x = (xs * self.alpha).sum(dim=0)  # Sum along K layers.\n","        return x"],"metadata":{"id":"kQaHGpk7h5As"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model_config = {\n","    \"n_users\": len(users['user_id']),\n","    \"m_items\": len(movies['movie_id']),\n","    \"embedding_size\": config_dict[\"embedding_size\"],\n","    \"num_layers\": config_dict[\"num_layers\"],\n","}"],"metadata":{"id":"4EpodI3t5AUE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2.3 Bayesian Personalized Ranking loss (BPR loss)\n","\n","BPR attempts to learn the correct rank-ordering of items for each user by maximizing the posterior probability (MAP) of the model parameters given a data set of observed user-item preferences and a chosen prior distribution. Each user’s observed items (implicit feedback) are assumed to be preferred over the unobserved items.\n","\n","To train the LightGCN model, we need an objective function that aligns with our goal for movie recommendation. We use the Bayesian Personalized Ranking (BPR) loss, which encourages observed user-item predictions to have increasingly higher values than unobserved ones, along with $ L_2 $ regularization:\n","$$ L_{BPR} = - \\sum_{u=1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln \\sigma(\\hat{y}_{ui} - \\hat{y}_{uj}) + \\lambda ||\\textbf{E}^{(0)} ||^2 $$\n","where $ \\textbf{E}^{(0)} $ is a matrix with column vectors being the 0-th layer embeddings to learn."],"metadata":{"id":"THIjBg2ey09O"}},{"cell_type":"code","source":["def getEmbedding(model, users, pos, neg, data, mask):\n","    \"\"\"\n","    INPUT:\n","        model: the LightGCN model you are training on\n","        users: this is the user index (note: use 0-indexed and not user number)\n","        pos: positive index corresponding to an item that the user like\n","        neg: negative index corresponding to an item that the user doesn't like\n","        data: the entire data, used to fetch all users and all items\n","        mask: Masking matrix indicating edges present in the current set\n","    \"\"\"\n","\n","    # assuming we always search for users and items by their indices\n","    all_users_items = model(\n","        model.embedding_user_item.weight.clone(), data[\"edge_index\"] * mask)\n","    all_users = all_users_items[:len(data[\"users\"])]\n","    all_items = all_users_items[len(data[\"users\"]):]\n","    users_emb = all_users[users]\n","    pos_emb = all_items[pos]\n","    neg_emb = all_items[neg]\n","    n_user = len(data[\"users\"])\n","    users_emb_ego = model.embedding_user_item(users)\n","    # offset the index to fetch embedding from user_item\n","    pos_emb_ego = model.embedding_user_item(pos + n_user)\n","    neg_emb_ego = model.embedding_user_item(neg + n_user)\n","    return users_emb, pos_emb, neg_emb, users_emb_ego, pos_emb_ego, neg_emb_ego\n","\n","def getUsersRating(model, users, data):\n","    \"\"\" Get the embedding of users\n","    INPUT:\n","        model: the LightGCN model you are training on\n","        users: this is the user index (note: use 0-indexed and not user number\n","        data: the entire data, used to fetch all users and all items\n","    \"\"\"\n","    all_users_items = model(\n","        model.embedding_user_item.weight.clone(), data[\"edge_index\"])\n","    all_users = all_users_items[:len(data[\"users\"])]\n","    items_emb = all_users_items[len(data[\"users\"]): ]\n","    users_emb = all_users[users.long()]\n","    rating = model.f(torch.matmul(users_emb, items_emb.t()))\n","    return rating\n","\n","def bpr_loss(model, users, pos, neg, data, mask):\n","    \"\"\" \n","    INPUT:\n","        model: the LightGCN model you are training on\n","        users: this is the user index (note: use 0-indexed and not user number)\n","        pos: positive index corresponding to an item that the user like\n","            (0-indexed, note to index items starting from 0)\n","        neg: negative index corresponding to an item that the user doesn't like\n","        data: the entire data, used to fetch all users and all items\n","        mask: Masking matrix indicating edges present in the current set\n","    OUTPUT:\n","        loss, reg_loss\n","    \"\"\"\n","\n","    assert len(users) == len(pos) and len(users) == len(neg)\n","    (users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0) = getEmbedding(\n","        model, users.long(), pos.long(), neg.long(), data, mask)\n","    \n","    reg_loss = (1/2) * (\n","        userEmb0.norm(2).pow(2) + \n","        posEmb0.norm(2).pow(2)  + \n","        negEmb0.norm(2).pow(2))/float(len(users)\n","        )\n","\n","    pos_scores = torch.mul(users_emb, pos_emb)\n","    pos_scores = torch.sum(pos_scores, dim=1)\n","    neg_scores = torch.mul(users_emb, neg_emb)\n","    neg_scores = torch.sum(neg_scores, dim=1)\n","    loss = torch.mean(torch.nn.functional.softplus(neg_scores - pos_scores))\n","    return loss, reg_loss\n","\n","### testing\n","lightGCN = LightGCN(model_config, device=device)\n","optimizer = optim.Adam(lightGCN.parameters(), lr=lr)\n","users = samples_train[:, 0:1]\n","pos = samples_train[:, 1:2]\n","neg = samples_train[:, 2:3]\n","\n","loss, reg_loss = bpr_loss(\n","    lightGCN, users, pos, neg, data, train_mask)\n","reg_loss = reg_loss * weight_decay\n","loss = loss + reg_loss\n","# loss_sum += loss.detach()\n","# loss.backward()\n","# optimizer.step()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"1B_KvUI3jsIa","executionInfo":{"status":"error","timestamp":1671646541924,"user_tz":-480,"elapsed":6,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"558ac790-83c7-410f-8917-1273df5387d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["use NORMAL distribution initilizer\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-69-dd4ddf1e3131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m loss, reg_loss = bpr_loss(\n\u001b[0m\u001b[1;32m     81\u001b[0m     lightGCN, users, pos, neg, data, train_mask)\n\u001b[1;32m     82\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-dd4ddf1e3131>\u001b[0m in \u001b[0;36mbpr_loss\u001b[0;34m(model, users, pos, neg, data, mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     (users_emb, pos_emb, neg_emb, userEmb0,  posEmb0, negEmb0) = getEmbedding(\n\u001b[0m\u001b[1;32m     58\u001b[0m         model, users.long(), pos.long(), neg.long(), data, mask)\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-dd4ddf1e3131>\u001b[0m in \u001b[0;36mgetEmbedding\u001b[0;34m(model, users, pos, neg, data, mask)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# assuming we always search for users and items by their indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     all_users_items = model(\n\u001b[0;32m---> 14\u001b[0;31m         model.embedding_user_item.weight.clone(), data[\"edge_index\"] * mask)\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mall_users\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_users_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"users\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mall_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_users_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"users\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3706) must match the size of tensor b (3883) at non-singleton dimension 1"]}]},{"cell_type":"markdown","source":["### 1.2.4 Training"],"metadata":{"id":"QNs1e6vG2RCO"}},{"cell_type":"code","source":["### training epoch\n","epochs_tracked = []\n","train_topks = []\n","val_topks = []\n","\n","for epoch in range(epochs):\n","    print(\"Training on the {} epoch\".format(epoch))\n","    lightGCN.train()\n","    loss_sum = 0\n","    # Shuffle the order of rows.\n","    samples_train = samples_train[torch.randperm(samples_train.size()[0])]\n","    for batch_idx in range(math.ceil(len(samples_train) / batch_size)):\n","        optimizer.zero_grad()\n","\n","        current_batch = samples_train[batch_idx*batch_size: (batch_idx+1)*batch_size]\n","\n","        # Shuffle the order of rows.\n","        current_batch = current_batch[torch.randperm(current_batch.size()[0])]\n","        users = current_batch[:, 0:1]\n","        pos = current_batch[:, 1:2]\n","        neg = current_batch[:, 2:3]\n","\n","        loss, reg_loss = bpr_loss(\n","            lightGCN, users, pos, neg, data, train_mask)\n","        reg_loss = reg_loss * weight_decay\n","        loss = loss + reg_loss\n","        loss_sum += loss.detach()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % config_dict[\"minibatch_per_print\"] == 0:\n","            all_users = torch.linspace(start=0, end=n_users - 1, steps=n_users).long()\n","            user_indices = current_batch[:, 0]\n","            user_indices = user_indices.repeat(2).long()\n","            item_indices = torch.cat((current_batch[:, 1], current_batch[:, 2])).long()\n","\n","            pred = getUsersRating(\n","                lightGCN, all_users, data)[user_indices, item_indices]\n","\n","            truth = data[\"edge_index\"][user_indices, item_indices]\n","            topk_precision, topk_recall = \\\n","                personalized_topk(pred, K, user_indices, data[\"edge_index\"])\n","\n","    if epoch % config_dict[\"epochs_per_print\"] == 0:\n","        epochs_tracked.append(epoch)\n","\n","        # evaluation on both the trainisng and validation set\n","        lightGCN.eval()\n","        # predict on the training set\n","\n","        users = samples_train[:, 0:1]\n","        user_indices = samples_train[:, 0]\n","        user_indices = user_indices.repeat(2).long()\n","        item_indices = torch.cat((samples_train[:, 1], samples_train[:, 2])).long()\n","\n","        pred = getUsersRating(\n","            lightGCN, users[:,0], data)[user_indices, item_indices]\n","\n","        truth = data[\"edge_index\"][users.long()[:,0]][user_indices, item_indices]\n","\n","        train_topk_precision, train_topk_recall = personalized_topk(\n","            pred, K, user_indices, data[\"edge_index\"])\n","        \n","        train_topks.append((train_topk_precision, train_topk_recall))\n","\n","        # predict on the validation set\n","        users_val = samples_val[:, 0:1]\n","        pos_val = samples_val[:, 1:2]\n","        neg_val = samples_val[:, 2:3]\n","        loss_val, reg_loss_val = bpr_loss(\n","            lightGCN, users_val, pos_val, neg_val, data, val_mask)\n","        reg_loss_val = reg_loss_val * weight_decay\n","\n","        # predict on the validation set\n","        user_indices = samples_val[:, 0]\n","        user_indices = user_indices.repeat(2).long()\n","        item_indices = torch.cat((samples_val[:, 1], samples_val[:, 2])).long()\n","        pred_val = getUsersRating(\n","            lightGCN, users_val[:,0], data)[user_indices, item_indices]\n","\n","        truth_val = data[\"edge_index\"][users_val.long()[:,0]][user_indices, item_indices]\n","        val_topk_precision, val_topk_recall = personalized_topk(\n","            pred_val, K, user_indices, data[\"edge_index\"])\n","        val_topks.append((val_topk_precision, val_topk_recall))"],"metadata":{"id":"tRhu8z-Y8_mb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1.2.5 Evaluation\n"],"metadata":{"id":"IbNMp-oP20IM"}},{"cell_type":"code","source":["def personalized_topk(pred, K, user_indices, edge_index):\n","    \"\"\"Computes TopK precision and recall.\n","\n","    Args:\n","        pred: Predicted similarities between user and item.\n","        K: Number of items to rank.\n","        user_indices: Indices of users for each prediction in `pred`.\n","        edge_index: User and item connection matrix.\n","\n","    Returns:\n","        Average Top K precision and recall for users in `user_indices`.\n","    \"\"\"\n","    per_user_preds = collections.defaultdict(list)\n","    for index, user in enumerate(user_indices):\n","        per_user_preds[user.item()].append(pred[index].item())\n","    precisions = 0.0\n","    recalls = 0.0\n","    for user, preds in per_user_preds.items():\n","        while len(preds) < K:\n","            preds.append(random.choice(range(edge_index.shape[1])))\n","        top_ratings, top_items = torch.topk(torch.tensor(preds), K)\n","        correct_preds = edge_index[user, top_items].sum().item()\n","        total_pos = edge_index[user].sum().item()\n","        precisions += correct_preds / K\n","        recalls += correct_preds / total_pos if total_pos != 0 else 0\n","    num_users = len(user_indices.unique())\n","    return precisions / num_users, recalls / num_users"],"metadata":{"id":"jCCg8GHT2oiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predict on the test set\n","lightGCN.eval()\n","print(\"Training completed after {} epochs\".format(epochs))\n","\n","users_test = samples_test[:, 0:1]\n","pos_test = samples_test[:, 1:2]\n","neg_test = samples_test[:, 2:3]\n","\n","loss_test, reg_loss_test = bpr_loss(\n","    lightGCN, users_test, pos_test, neg_test, data, test_mask)\n","reg_loss_test = reg_loss_test * weight_decay\n","\n","# predict on the test set\n","user_indices = samples_test[:, 0]\n","user_indices = user_indices.repeat(2).long()\n","item_indices = torch.cat((samples_test[:, 1], samples_test[:, 2])).long()\n","pred_test = getUsersRating(lightGCN, users_test[:,0], data)\\\n","    [user_indices, item_indices]\n","truth_test = data[\"edge_index\"][users_test.long()[:,0]]\\\n","    [user_indices, item_indices]\n","test_topk_precision, test_topk_recall = personalized_topk(\n","    pred_test, K, user_indices, data[\"edge_index\"])"],"metadata":{"id":"e69BBecA2_Xg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute baseline metrics using matrix factorization.\n","baseline_pred = matrix_factorization(\n","        data[\"edge_index\"].detach().cpu().numpy(),\n","        config_dict[\"mf_rank\"])[user_indices.cpu(), item_indices.cpu()]\n","baseline_topk_precision, baseline_topk_recall = \\\n","        personalized_topk(baseline_pred, K, user_indices, data[\"edge_index\"])\n","print(\"Baseline (PARAFAC matrix factorization) produces \",\n","      \"Top K precision = {}, recall = {}.\".format(baseline_topk_precision,\n","                                                  baseline_topk_recall))"],"metadata":{"id":"XajmS4X43MCi"},"execution_count":null,"outputs":[]}]}