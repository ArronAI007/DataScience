{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"colab":{"provenance":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"bwjRxHmhHsjw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671646770242,"user_tz":-480,"elapsed":528,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"44d86bdb-b145-4aab-8c7c-9110f4d0b0ab"},"source":["!wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n","!unzip ml-100k.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-21 18:19:28--  https://files.grouplens.org/datasets/movielens/ml-100k.zip\n","Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n","Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4924029 (4.7M) [application/zip]\n","Saving to: ‘ml-100k.zip’\n","\n","ml-100k.zip         100%[===================>]   4.70M  26.8MB/s    in 0.2s    \n","\n","2022-12-21 18:19:29 (26.8 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n","\n","Archive:  ml-100k.zip\n","   creating: ml-100k/\n","  inflating: ml-100k/allbut.pl       \n","  inflating: ml-100k/mku.sh          \n","  inflating: ml-100k/README          \n","  inflating: ml-100k/u.data          \n","  inflating: ml-100k/u.genre         \n","  inflating: ml-100k/u.info          \n","  inflating: ml-100k/u.item          \n","  inflating: ml-100k/u.occupation    \n","  inflating: ml-100k/u.user          \n","  inflating: ml-100k/u1.base         \n","  inflating: ml-100k/u1.test         \n","  inflating: ml-100k/u2.base         \n","  inflating: ml-100k/u2.test         \n","  inflating: ml-100k/u3.base         \n","  inflating: ml-100k/u3.test         \n","  inflating: ml-100k/u4.base         \n","  inflating: ml-100k/u4.test         \n","  inflating: ml-100k/u5.base         \n","  inflating: ml-100k/u5.test         \n","  inflating: ml-100k/ua.base         \n","  inflating: ml-100k/ua.test         \n","  inflating: ml-100k/ub.base         \n","  inflating: ml-100k/ub.test         \n"]}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-05T14:43:46.923119Z","start_time":"2020-08-05T14:43:45.194863Z"},"id":"ELhG4LHtHiLZ","executionInfo":{"status":"ok","timestamp":1671646774247,"user_tz":-480,"elapsed":4008,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.parallel\n","import torch.optim as optim\n","import torch.utils.data\n","from torch.autograd import Variable"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tIwOCugHHiLv"},"source":["# 1) AutoEncoder"]},{"cell_type":"markdown","metadata":{"id":"kZMAFCjnHiLn"},"source":["## Pre-Processing"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-05T14:45:46.038051Z","start_time":"2020-08-05T14:45:45.964054Z"},"id":"0ZKW8BHtHiLv","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1671646774248,"user_tz":-480,"elapsed":11,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"542e13a9-9053-470b-c3a9-8b9ef7d32ff8"},"source":["training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t', names=['user_id', 'movie_id', 'rating', 'time'])\n","test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t', names=['user_id', 'movie_id', 'rating', 'time'])\n","training_set.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   user_id  movie_id  rating       time\n","0        1         1       5  874965758\n","1        1         2       3  876893171\n","2        1         3       4  878542960\n","3        1         4       3  876893119\n","4        1         5       3  889751712"],"text/html":["\n","  <div id=\"df-583f1a17-6d8a-4a48-bb11-af04e493772d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>movie_id</th>\n","      <th>rating</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>874965758</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>876893171</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>878542960</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>876893119</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>889751712</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-583f1a17-6d8a-4a48-bb11-af04e493772d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-583f1a17-6d8a-4a48-bb11-af04e493772d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-583f1a17-6d8a-4a48-bb11-af04e493772d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["matrix_train = training_set.groupby(['user_id', 'movie_id'])['rating'].mean().unstack().fillna(0)\n","matrix_test = test_set.groupby(['user_id', 'movie_id'])['rating'].mean().unstack().fillna(0)\n","matrix_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"tilZg1relKPm","executionInfo":{"status":"ok","timestamp":1671646811831,"user_tz":-480,"elapsed":557,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"ce58aff2-4f68-41fc-e7bd-4abc8c7da390"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n","user_id                                                               ...   \n","1          5.0   3.0   4.0   3.0   3.0   0.0   4.0   1.0   5.0   0.0  ...   \n","2          4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   \n","3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n","\n","movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n","user_id                                                               \n","1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","4          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","5          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","\n","[5 rows x 1650 columns]"],"text/html":["\n","  <div id=\"df-4b124202-aa01-4693-96b8-79f74397d714\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>movie_id</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>...</th>\n","      <th>1673</th>\n","      <th>1674</th>\n","      <th>1675</th>\n","      <th>1676</th>\n","      <th>1677</th>\n","      <th>1678</th>\n","      <th>1679</th>\n","      <th>1680</th>\n","      <th>1681</th>\n","      <th>1682</th>\n","    </tr>\n","    <tr>\n","      <th>user_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>5.0</td>\n","      <td>3.0</td>\n","      <td>4.0</td>\n","      <td>3.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>5.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1650 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b124202-aa01-4693-96b8-79f74397d714')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b124202-aa01-4693-96b8-79f74397d714 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b124202-aa01-4693-96b8-79f74397d714');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["nb_movies = len(matrix_train.columns)\n","nb_users = len(matrix_train)\n","training_set = np.array(matrix_train, dtype='int')\n","test_set = np.array(matrix_test, dtype='int')\n","training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)\n","print(training_set.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzLSPGg8luR0","executionInfo":{"status":"ok","timestamp":1671386764182,"user_tz":-480,"elapsed":514,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"f56eea61-a98b-4557-f651-9b48e5d9623a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([943, 1650])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Kp2fVmbhHiLx"},"source":["## Model Training"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-05T14:46:49.686218Z","start_time":"2020-08-05T14:46:49.675638Z"},"id":"Tom7uH4uHiLy"},"source":["class SAE(nn.Module):\n","    def __init__(self, ):\n","        super(SAE, self).__init__()\n","        self.fc1 = nn.Linear(nb_movies, 20)\n","        self.fc2 = nn.Linear(20, 10)\n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-05T14:54:11.894843Z","start_time":"2020-08-05T14:46:50.430969Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"bQcdzUWEHiLz","executionInfo":{"status":"ok","timestamp":1661609480951,"user_tz":-480,"elapsed":7827,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"294b606c-9116-48e8-895d-f2b577e9547b"},"source":["nb_epoch = 5\n","for epoch in range(1, nb_epoch + 1):\n","    train_loss = 0\n","    s = 0.\n","\n","    for id_user in range(nb_users):\n","        input = Variable(training_set[id_user]).unsqueeze(0)\n","        target = input.clone()\n","        if torch.sum(target.data > 0) > 0:\n","            output = sae(input)\n","            target.require_grad = False\n","            output[target == 0] = 0\n","            loss = criterion(output, target)\n","            mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-9)\n","            loss.backward()\n","            train_loss += np.sqrt(loss.data * mean_corrector)\n","            s += 1.\n","            optimizer.step()\n","    print('epoch: '+str(epoch)+'loss: '+ str(train_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1loss: tensor(1.7622)\n","epoch: 2loss: tensor(1.0947)\n","epoch: 3loss: tensor(1.0526)\n","epoch: 4loss: tensor(1.0379)\n","epoch: 5loss: tensor(1.0306)\n"]}]},{"cell_type":"markdown","metadata":{"id":"kbm1blhxHiL0"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2020-08-05T14:54:12.212997Z","start_time":"2020-08-05T14:54:11.898015Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"HVB2OqpCHiL0","executionInfo":{"status":"ok","timestamp":1619792267016,"user_tz":-480,"elapsed":267950,"user":{"displayName":"Chan Chee Kean","photoUrl":"","userId":"05792587367281359063"}},"outputId":"241bf1bf-59e8-492b-92fe-039e396ada51"},"source":["test_loss = 0\n","s = 0.\n","for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = Variable(test_set[id_user]).unsqueeze(0)\n","    if torch.sum(target.data > 0) > 0:\n","        output = sae(input)\n","        target.require_grad = False\n","        output[target == 0] = 0\n","        loss = criterion(output, target)\n","        mean_corrector = nb_movies / float(torch.sum(target.data > 0) + 1e-10)\n","        test_loss += np.sqrt(loss.data * mean_corrector)\n","        s += 1.\n","print('test loss: ' + str(test_loss / s))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test loss: tensor(0.9513)\n"],"name":"stdout"}]},{"cell_type":"markdown","source":["# 2) MultiVAE\n","\n","<img src=\"https://miro.medium.com/max/750/1*uk_7iIr7wObUAqIuYJ5Yzw.webp\">\n","\n","https://github.com/khanhnamle1994/MetaRec/blob/master/Autoencoders-Experiments/VAE-PyTorch/MultVAE.py"],"metadata":{"id":"Aik29ee3CBfx"}},{"cell_type":"code","source":["hyper_params = {\n","    \"enc_dims\": [300, 100],\n","    \"dropout\": 0.5,\n","    \"anneal_cap\": 0.2,\n","    \"total_anneal_steps\": 200000,\n","    \"epochs\": 500,\n","    \"batch_size\": 512,\n","    \"optimizer\": \"Adam\",\n","    \"learning_rate\": 0.01\n","}\n","\n","class VAEConfig:\n","    def __init__(self, **kwargs):\n","        for key, value in kwargs.items():\n","            setattr(self, key, value)\n","\n","config = VAEConfig(**hyper_params)"],"metadata":{"id":"7PTt6FIrCzLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultVAE(nn.Module):\n","    \"\"\"\n","    Variational Autoencoder with Multninomial Likelihood model class\n","    \"\"\"\n","    def __init__(self, model_conf, num_users, num_items, device):\n","        \"\"\"\n","        :param model_conf: model configuration\n","        :param num_users: number of users\n","        :param num_items: number of items\n","        :param device: choice of device\n","        \"\"\"\n","\n","        super(MultVAE, self).__init__()\n","        self.num_users = num_users\n","        self.num_items = num_items\n","        self.enc_dims = [self.num_items] + model_conf.enc_dims\n","        self.dec_dims = self.enc_dims[::-1]\n","        self.dims = self.enc_dims + self.dec_dims[1:]\n","        self.total_anneal_steps = model_conf.total_anneal_steps\n","        self.anneal_cap = model_conf.anneal_cap\n","        self.dropout = model_conf.dropout\n","        self.eps = 1e-6\n","        self.anneal = 0.\n","        self.update_count = 0\n","        self.device = device\n","\n","        self.encoder = nn.ModuleList()\n","\n","        for i, (d_in, d_out) in enumerate(zip(self.enc_dims[:-1], self.enc_dims[1:])):\n","            if i == len(self.enc_dims[:-1]) - 1:\n","                d_out *= 2\n","\n","            self.encoder.append(nn.Linear(d_in, d_out))\n","\n","            if i != len(self.enc_dims[:-1]) - 1:\n","                self.encoder.append(nn.Tanh())\n","\n","        self.decoder = nn.ModuleList()\n","        for i, (d_in, d_out) in enumerate(zip(self.dec_dims[:-1], self.dec_dims[1:])):\n","            self.decoder.append(nn.Linear(d_in, d_out))\n","            if i != len(self.dec_dims[:-1]) - 1:\n","                self.decoder.append(nn.Tanh())\n","\n","        self.to(self.device)\n","\n","    def forward(self, rating_matrix):\n","        \"\"\"\n","        :param rating_matrix: rating matrix\n","        \"\"\"\n","\n","        # (n_user, n_item)\n","        h = F.dropout(F.normalize(rating_matrix), p=self.dropout, training=self.training)\n","\n","        # (n_user, n_item) --> (n_user, enc_dims * 2)\n","        for layer in self.encoder:\n","            h = layer(h)\n","\n","        # (n_user, enc_dims)\n","        mu_q = h[:, :self.enc_dims[-1]]\n","        logvar_q = h[:, self.enc_dims[-1]:] \n","        std_q = torch.exp(0.5 * logvar_q)\n","        epsilon = torch.zeros_like(std_q).normal_(mean=0, std=0.01)\n","        sampled_z = mu_q + self.training * epsilon * std_q\n","        output = sampled_z\n","\n","        # (n_user, enc_dims) --> (n_user, n_item)\n","        for layer in self.decoder:\n","            output = layer(output)\n","\n","        if self.training:\n","            kl_loss = (\n","                (0.5 * (-logvar_q + torch.exp(logvar_q) + torch.pow(mu_q, 2) - 1)).sum(1)\n","                ).mean()\n","            return output, kl_loss\n","        else:\n","            return output\n","\n","    def train_one_epoch(self, dataset, optimizer, batch_size, verbose):\n","        \"\"\"\n","        Train model for one epoch\n","        :param dataset: given data\n","        :param optimizer: choice of optimizer\n","        :param batch_size: batch size\n","        :param verbose: verbose\n","        :return: model loss\n","        \"\"\"\n","        self.train()\n","\n","        # user, item, rating pairs\n","        train_matrix = dataset.train_matrix\n","        num_training = train_matrix.shape[0]\n","        num_batches = int(np.ceil(num_training / batch_size))\n","        perm = np.random.permutation(num_training)\n","\n","        loss = 0.0\n","        for b in range(num_batches):\n","            optimizer.zero_grad()\n","\n","            if (b + 1) * batch_size >= num_training:\n","                batch_idx = perm[b * batch_size:]\n","            else:\n","                batch_idx = perm[b * batch_size: (b + 1) * batch_size]\n","            batch_matrix = torch.FloatTensor(train_matrix[batch_idx].toarray()).to(self.device)\n","\n","            if self.total_anneal_steps > 0:\n","                self.anneal = min(self.anneal_cap, 1. * self.update_count / self.total_anneal_steps)\n","            else:\n","                self.anneal = self.anneal_cap\n","\n","            pred_matrix, kl_loss = self.forward(batch_matrix)\n","\n","            # cross_entropy\n","            # F.log_softmax([0.001, 0.1, 1]) --> [-1.5727, -1.4737, -0.5737]\n","            # after multiplication, only 1 is taken account\n","            ce_loss = -(F.log_softmax(pred_matrix, 1) * batch_matrix).sum(1).mean()\n","            batch_loss = ce_loss + kl_loss * self.anneal\n","            batch_loss.backward()\n","            optimizer.step()\n","            self.update_count += 1\n","\n","            loss += batch_loss\n","            if verbose and b % 50 == 0:\n","                print('(%3d / %3d) loss = %.4f' % (b, num_batches, batch_loss))\n","        return loss\n","\n","    def predict(self, eval_users, eval_pos, test_batch_size):\n","        \"\"\"\n","        Predict the model on test set\n","        :param eval_users: evaluation (test) user\n","        :param eval_pos: position of the evaluated (test) item\n","        :param test_batch_size: batch size for test set\n","        :return: predictions\n","        \"\"\"\n","        with torch.no_grad():\n","            input_matrix = torch.FloatTensor(eval_pos.toarray()).to(self.device)\n","            preds = np.zeros_like(input_matrix)\n","\n","            num_data = input_matrix.shape[0]\n","            num_batches = int(np.ceil(num_data / test_batch_size))\n","            perm = list(range(num_data))\n","            for b in range(num_batches):\n","                if (b + 1) * test_batch_size >= num_data:\n","                    batch_idx = perm[b * test_batch_size:]\n","                else:\n","                    batch_idx = perm[b * test_batch_size: (b + 1) * test_batch_size]\n","                test_batch_matrix = input_matrix[batch_idx]\n","                batch_pred_matrix = self.forward(test_batch_matrix)\n","                batch_pred_matrix.masked_fill(test_batch_matrix.bool(), float('-inf'))\n","                preds[batch_idx] = batch_pred_matrix.detach().cpu().numpy()\n","        return preds\n","\n","### testing\n","model = MultVAE(config, matrix_train.shape[0], matrix_train.shape[1], 'cpu')\n","output, kl_loss = model(torch.Tensor(matrix_train.values))\n","ce_loss = -(F.log_softmax(output, 1) * torch.Tensor(matrix_train.values)).sum(1).mean()\n","print(f\"Loss: {kl_loss} \\nOutput Size: {output.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUHHZwt9CBog","executionInfo":{"status":"ok","timestamp":1671386771474,"user_tz":-480,"elapsed":501,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"a9eb2cae-8cb8-4148-ca94-87151a7364a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.09954748302698135 \n","Output Size: torch.Size([943, 1650])\n"]}]}]}