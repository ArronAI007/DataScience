{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 1) Keybert (scratch)\n","\n","There are many powerful techniques that perform keywords extraction (e.g. Rake, YAKE!, TF-IDF). However, they are mainly based on the statistical properties of the text and donâ€™t necessarily take into account the semantic aspects of the full document.\n","\n","[Reference](https://towardsdatascience.com/how-to-extract-relevant-keywords-with-keybert-6e7b3cf889ae)"],"metadata":{"id":"O5kkJ5VjRD0h"}},{"cell_type":"code","source":["!pip install sentence-transformers keybert keyphrase-vectorizers\n","!pip install textacy==0.11.0 -qqqq\n","!python -m spacy download en_core_web_sm -qqq"],"metadata":{"id":"Mtx5VQg-Rcz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import itertools\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from keybert import KeyBERT\n","from keyphrase_vectorizers import KeyphraseCountVectorizer\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"sXar9YbkRJh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["doc = \"\"\"\n","         Supervised learning is the machine learning task of\n","         learning a function that maps an input to an output based\n","         on example input-output pairs.[1] It infers a function\n","         from labeled training data consisting of a set of\n","         training examples.[2] In supervised learning, each\n","         example is a pair consisting of an input object\n","         (typically a vector) and a desired output value (also\n","         called the supervisory signal). A supervised learning\n","         algorithm analyzes the training data and produces an\n","         inferred function, which can be used for mapping new\n","         examples. An optimal scenario will allow for the algorithm\n","         to correctly determine the class labels for unseen\n","         instances. This requires the learning algorithm to\n","         generalize from the training data to unseen situations\n","         in a 'reasonable' way (see inductive bias).\n","      \"\"\""],"metadata":{"id":"v9-sS4T4YPM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract candidate words/phrases\n","# use countvectorizer to remove stopword and define ngram\n","n_gram_range = (1, 1)\n","stop_words = \"english\"\n","\n","count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([doc])\n","candidates = count.get_feature_names_out()\n","print(candidates, '\\n')\n","\n","# embedding with distilbert\n","model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n","doc_embedding = model.encode([doc])\n","candidate_embeddings = model.encode(candidates)\n","\n","print(doc_embedding.shape)\n","print(candidate_embeddings.shape)\n","print(\"\\m\")\n","\n","# find top most similar candidates to document\n","top_n = 5\n","distances = cosine_similarity(doc_embedding, candidate_embeddings)\n","keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n","print(keywords, '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nd-_H2T9RGeH","executionInfo":{"status":"ok","timestamp":1657897077587,"user_tz":-480,"elapsed":1210,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"5ea8286d-fa4f-44b8-a645-e973437a0d90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['algorithm' 'allow' 'analyzes' 'based' 'bias' 'called' 'class'\n"," 'consisting' 'correctly' 'data' 'desired' 'determine' 'example'\n"," 'examples' 'function' 'generalize' 'inductive' 'inferred' 'infers'\n"," 'input' 'instances' 'labeled' 'labels' 'learning' 'machine' 'mapping'\n"," 'maps' 'new' 'object' 'optimal' 'output' 'pair' 'pairs' 'produces'\n"," 'reasonable' 'requires' 'scenario' 'set' 'signal' 'situations'\n"," 'supervised' 'supervisory' 'task' 'training' 'typically' 'unseen' 'used'\n"," 'value' 'vector' 'way'] \n","\n","(1, 768)\n","(50, 768)\n","\\m\n","['mapping', 'class', 'training', 'algorithm', 'learning'] \n","\n"]}]},{"cell_type":"code","source":["# some words are too similar, maximize similarities(doc, word), min similarities(word, word)\n","nr_candidates = 10\n","distances_candidates = cosine_similarity(candidate_embeddings, candidate_embeddings)\n","words_idx = list(distances.argsort()[0][-nr_candidates:])\n","words_vals = [candidates[index] for index in words_idx]\n","distances_candidates = distances_candidates[np.ix_(words_idx, words_idx)]\n","print(words_vals)\n","print(distances_candidates.shape)\n","\n","# Calculate the combination of words that are the least similar to each other to ensure diversity\n","min_sim = np.inf\n","candidate = None\n","for combination in itertools.combinations(range(len(words_idx)), top_n):\n","    sim = sum([distances_candidates[i][j] for i in combination for j in combination if i != j])\n","    if sim < min_sim:\n","        candidate = combination\n","        min_sim = sim\n","\n","result = [words_vals[idx] for idx in candidate]\n","print(\"After Minimizing Distance\", result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3-OjswxXXOZ","executionInfo":{"status":"ok","timestamp":1657897561891,"user_tz":-480,"elapsed":524,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"ad0ae752-a9f9-425d-8ecf-02bfc73c217f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['maps', 'task', 'input', 'analyzes', 'supervised', 'mapping', 'class', 'training', 'algorithm', 'learning']\n","(10, 10)\n","After Minimizing Distance ['maps', 'input', 'class', 'training', 'algorithm']\n"]}]},{"cell_type":"code","source":["# Maximal Marginal Relevance tries to minimize redundancy and maximize the diversity\n","# of results in text summarization tasks\n","\n","# Extract similarity within words, and between words and the document\n","word_doc_similarity = cosine_similarity(candidate_embeddings, doc_embedding)\n","word_similarity = cosine_similarity(candidate_embeddings)\n","print(word_doc_similarity.shape)\n","print(word_similarity.shape)\n","\n","# Initialize candidates and already choose best keyword/keyphras\n","keywords_idx = [np.argmax(word_doc_similarity)]\n","candidates_idx = [i for i in range(len(candidates)) if i != keywords_idx[0]]\n","print(keywords_idx)\n","\n","# Extract similarities within candidates\n","# between candidates and selected keywords/phrases\n","\n","diversity = 0.7\n","for _ in range(top_n - 1):\n","    candidate_similarities = word_doc_similarity[candidates_idx, :]\n","    target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n","\n","    # Calculate MMR\n","    mmr = (1 - diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n","    mmr_idx = candidates_idx[np.argmax(mmr)]\n","\n","    # Update keywords & candidates\n","    keywords_idx.append(mmr_idx)\n","    candidates_idx.remove(mmr_idx)\n","\n","print([candidates[idx] for idx in keywords_idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OskuR6oUXdZM","executionInfo":{"status":"ok","timestamp":1657898527498,"user_tz":-480,"elapsed":4,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"45e2687b-8405-4def-eca8-e8d91a3734ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(50, 1)\n","(50, 50)\n","[23]\n","['learning', 'maps', 'function', 'algorithm', 'new']\n"]}]},{"cell_type":"markdown","source":["# 2) Keybert Package with Keyphase Vectorizer\n","\n","First, the document texts are annotated with spaCy part-of-speech tags.\n","\n","Second, keyphrases are extracted from the document texts whose part-of-speech tags match a predefined regex pattern.\n","\n","By default, the vectorizers extract keyphrases that have zero or more adjectives, followed by one or more nouns using the English spaCy part-of-speech tags. Finally, the vectorizers calculate document-keyphrase matrices. Apart from the matrices, the package can also provide us with the keyphrases extracted via part-of-speech."],"metadata":{"id":"J6EveLq-eAal"}},{"cell_type":"code","source":["# keyphase count vectorizer, no ngram required\n","count = KeyphraseCountVectorizer(stop_words=stop_words).fit([doc])\n","print(count.get_feature_names_out())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0Mm8OCxhXk5","executionInfo":{"status":"ok","timestamp":1657899690320,"user_tz":-480,"elapsed":1759,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"8961c8fa-f468-4cf0-cf37-067c9ce663fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['learning' 'supervised learning' 'training data' 'function' 'algorithm'\n"," 'machine' 'task' 'vector' 'output pairs.[1' 'input object'\n"," 'training examples.[2' 'unseen situations' 'example' 'optimal scenario'\n"," 'supervisory signal' 'set' 'input' 'output value' 'example input'\n"," 'instances' 'pair' 'way' 'class labels' 'inductive bias' 'output'\n"," 'learning algorithm' 'examples']\n"]}]},{"cell_type":"code","source":["docs = [\"\"\"Supervised learning is the machine learning task of learning a function that\n","         maps an input to an output based on example input-output pairs. It infers a\n","         function from labeled training data consisting of a set of training examples.\n","         In supervised learning, each example is a pair consisting of an input object\n","         (typically a vector) and a desired output value (also called the supervisory signal).\n","         A supervised learning algorithm analyzes the training data and produces an inferred function,\n","         which can be used for mapping new examples. An optimal scenario will allow for the\n","         algorithm to correctly determine the class labels for unseen instances. This requires\n","         the learning algorithm to generalize from the training data to unseen situations in a\n","         'reasonable' way (see inductive bias).\"\"\",\n","\n","        \"\"\"Keywords are defined as phrases that capture the main topics discussed in a document.\n","        As they offer a brief yet precise summary of document content, they can be utilized for various applications.\n","        In an information retrieval environment, they serve as an indication of document relevance for users, as the list\n","        of keywords can quickly help to determine whether a given document is relevant to their interest.\n","        As keywords reflect a document's main topics, they can be utilized to classify documents into groups\n","        by measuring the overlap between the keywords assigned to them. Keywords are also used proactively\n","        in information retrieval.\"\"\"]\n","\n","# KeyBERT\n","sentence_model = SentenceTransformer(\"xlm-r-bert-base-nli-stsb-mean-tokens\", device=\"cuda\")\n","kw_model = KeyBERT(model=sentence_model)\n","result = kw_model.extract_keywords(docs=docs, keyphrase_ngram_range=(1, 2),\n","                                    stop_words='english', use_mmr=True, diversity=0.5)\n","print(result)\n","\n","# keybert with keyphase extractor\n","kw_model = KeyBERT()\n","result = kw_model.extract_keywords(docs=docs, vectorizer=KeyphraseCountVectorizer())\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmKGpZ-eeB7C","executionInfo":{"status":"ok","timestamp":1657899896531,"user_tz":-480,"elapsed":6117,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"5306a1aa-e1ee-4bfc-c1cf-edb1ba77a681"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2it [00:00, 345.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[[('machine learning', 0.6824), ('task learning', 0.7043), ('learning function', 0.7053), ('learning machine', 0.7085), ('analyzes training', 0.7145)], [('overlap keywords', 0.5512), ('keywords assigned', 0.5652), ('keywords reflect', 0.5749), ('list keywords', 0.5794), ('keywords defined', 0.5807)]]\n"]},{"output_type":"stream","name":"stderr","text":["2it [00:00, 800.36it/s]"]},{"output_type":"stream","name":"stdout","text":["[[('learning', 0.4813), ('training data', 0.5271), ('learning algorithm', 0.5632), ('supervised learning', 0.6779), ('supervised learning algorithm', 0.6992)], [('document content', 0.3988), ('information retrieval environment', 0.5166), ('information retrieval', 0.5792), ('keywords', 0.6046), ('document relevance', 0.633)]]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# 3) Textacy\n","\n","https://towardsdatascience.com/keyword-extraction-python-tf-idf-textrank-topicrank-yake-bert-7405d51cd839"],"metadata":{"id":"iGFPQX9aj-Ct"}},{"cell_type":"code","source":["import textacy\n","from textacy.extract.keyterms import yake, scake, sgrank, textrank\n","\n","docs = [\"\"\"Supervised learning is the machine learning task of learning a function that\n","         maps an input to an output based on example input-output pairs. It infers a\n","         function from labeled training data consisting of a set of training examples.\n","         In supervised learning, each example is a pair consisting of an input object\n","         (typically a vector) and a desired output value (also called the supervisory signal).\n","         A supervised learning algorithm analyzes the training data and produces an inferred function,\n","         which can be used for mapping new examples. An optimal scenario will allow for the\n","         algorithm to correctly determine the class labels for unseen instances. This requires\n","         the learning algorithm to generalize from the training data to unseen situations in a\n","         'reasonable' way (see inductive bias).\"\"\",\n","\n","        \"\"\"Keywords are defined as phrases that capture the main topics discussed in a document.\n","        As they offer a brief yet precise summary of document content, they can be utilized for various applications.\n","        In an information retrieval environment, they serve as an indication of document relevance for users, as the list\n","        of keywords can quickly help to determine whether a given document is relevant to their interest.\n","        As keywords reflect a document's main topics, they can be utilized to classify documents into groups\n","        by measuring the overlap between the keywords assigned to them. Keywords are also used proactively\n","        in information retrieval.\"\"\"]\n","\n","doc = textacy.make_spacy_doc(docs[0], \"en_core_web_sm\")\n","print(yake(doc, normalize='lemma', ngrams=(1, 2)), '\\n')\n","print(scake(doc, normalize='lemma'), '\\n')\n","print(sgrank(doc, normalize='lemma'), '\\n')\n","print(textrank(doc, normalize='lemma'), '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aYhSpnoYj_pf","executionInfo":{"status":"ok","timestamp":1657900523099,"user_tz":-480,"elapsed":332,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"fc4d2a7f-4eac-4ba9-d3c7-4a0658cc68d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('example', 0.3634354740148829), ('learning', 0.3705974051722146), ('training', 0.3718801713053885), ('function', 0.40704093462685076), ('input', 0.4170577044400542), ('output', 0.4199299663859866), ('algorithm', 0.42832637489640263), ('datum', 0.42992518289069875), ('pair', 0.5118569748358457), ('supervised', 0.5181712859829104)] \n","\n","[('supervised learning algorithm', 1173.2634871773075), ('example input', 393.35091441034865), ('training example', 392.90889155484166), ('training datum', 246.50911289502568), ('new example', 230.7359879626814), ('function', 220.29545454545456), ('output pair', 205.37226127377158), ('input object', 172.43905801336618), ('output value', 149.74645744796777), ('machine', 53.34545454545455)] \n","\n","[('training datum', 0.25063587325424164), ('supervised learning algorithm', 0.09145589706469866), ('training example', 0.06583222607866272), ('input object', 0.05784336111980621), ('output value', 0.0494875530956109), ('supervisory signal', 0.04764306107307626), ('new example', 0.03042832189503662), ('optimal scenario', 0.02954000596812543), ('function', 0.026973721134564442), ('output pair', 0.023500150264128213)] \n","\n","[('supervised learning algorithm', 0.045918445775443316), ('example input', 0.041483953063553625), ('training example', 0.04065544375804614), ('output pair', 0.03567577316898379), ('new example', 0.03199508413586974), ('output value', 0.030449466692285043), ('training datum', 0.03042395964730821), ('input object', 0.025235245144673513), ('unseen situation', 0.023082807329666857), ('unseen instance', 0.022980119985617123)] \n","\n"]}]}]}