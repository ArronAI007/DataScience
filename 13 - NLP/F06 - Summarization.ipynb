{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","import nltk\n","import random\n","import math\n","import time\n","import torch\n","import torch.nn.functional as F\n","import spacy\n","from tqdm import tqdm\n","spacy_en = spacy.load('en_core_web_sm')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8_P-cucOOWu","executionInfo":{"status":"ok","timestamp":1658216451741,"user_tz":-480,"elapsed":10686,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"096d640d-fd17-4d24-95de-925334192cf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# 1) LSTM (Encoder + Decoder)"],"metadata":{"id":"V-JdFuRYCk1n"}},{"cell_type":"code","source":["stop_words = stopwords.words('english')\n","\n","def preprocess(text):\n","    text = text.lower() # lowercase\n","    text = text.split() \n","    for i in range(len(text)):\n","        word = text[i]\n","    text = \" \".join(text)\n","    text = text.split()\n","    newtext = []\n","    for word in text:\n","        if word not in stop_words:\n","            newtext.append(word)\n","    text = \" \".join(newtext)\n","    text = text.replace(\"'s\",'')\n","    text = re.sub(r'\\(.*\\)','',text)\n","    text = re.sub(r'[^a-zA-Z0-9. ]','',text)\n","    text = re.sub(r'\\.',' . ',text)\n","    return text\n","\n","df = pd.read_csv(\n","    \"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", \n","    encoding='utf-8'\n",")\n","df['headlines'] = df['headlines'].apply(lambda x:preprocess(x))\n","df['text'] = df['text'].apply(lambda x:preprocess(x))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ptYr6JkxcXaC","executionInfo":{"status":"ok","timestamp":1658216491230,"user_tz":-480,"elapsed":39492,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"fea015db-472d-4a5b-e332-6e2d53d19687"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           headlines  \\\n","0  upgrad learner switches career ml  al 90 salar...   \n","1   delhi techie wins free food swiggy one year cred   \n","2  new zealand end rohit sharmaled india 12match ...   \n","3  aegon life iterm insurance plan helps customer...   \n","4           known hirani yrs metoo claims true sonam   \n","\n","                                                text  \n","0  saurav kant alumnus upgrad iiitb pg program ma...  \n","1  kunal shah credit card bill payment platform c...  \n","2  new zealand defeated india 8 wickets fourth od...  \n","3  aegon life iterm insurance plan customers enjo...  \n","4  speaking sexual harassment allegations rajkuma...  "],"text/html":["\n","  <div id=\"df-d824a346-d47d-4e2f-a524-73bb69ff8baa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>upgrad learner switches career ml  al 90 salar...</td>\n","      <td>saurav kant alumnus upgrad iiitb pg program ma...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>delhi techie wins free food swiggy one year cred</td>\n","      <td>kunal shah credit card bill payment platform c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>new zealand end rohit sharmaled india 12match ...</td>\n","      <td>new zealand defeated india 8 wickets fourth od...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>aegon life iterm insurance plan helps customer...</td>\n","      <td>aegon life iterm insurance plan customers enjo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>known hirani yrs metoo claims true sonam</td>\n","      <td>speaking sexual harassment allegations rajkuma...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d824a346-d47d-4e2f-a524-73bb69ff8baa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d824a346-d47d-4e2f-a524-73bb69ff8baa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d824a346-d47d-4e2f-a524-73bb69ff8baa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["### create vocab index\n","\n","# start and end of sentence \n","SOS_token = 100\n","EOS_token = 101\n","PAD_TOKEN = 0\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\", PAD_TOKEN: \"PAD\"}\n","        self.n_words = 3  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in spacy_en.tokenizer(sentence):\n","            self.addWord(word.text)\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","trg_lang = Lang(df['headlines'])\n","src_lang = Lang(df['text'])\n","\n","for line in df['headlines'].tolist():\n","    trg_lang.addSentence(line)\n","\n","for line in df['text'].tolist():\n","    src_lang.addSentence(line)\n","\n","print(trg_lang.n_words)\n","print(src_lang.n_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kw_GQV0v9uc","executionInfo":{"status":"ok","timestamp":1658216514033,"user_tz":-480,"elapsed":22809,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"e68f9829-15c6-4bac-9803-4764e75b56e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["41147\n","99924\n"]}]},{"cell_type":"code","source":["### dataset\n","\n","from torch.utils.data import DataLoader, Dataset, random_split\n","\n","class News_Dataset(Dataset):\n","    def __init__(self, src, trg, src_lang, trg_lang, max_len=256):\n","        self.max_len = max_len\n","        self.src = self.tokenize(src, src_lang, 128)\n","        self.trg = self.tokenize(trg, trg_lang, 32)\n","        \n","    def tokenize(self, sentence_list, lang, max_len):\n","        token_out = []\n","        for sentence in sentence_list:\n","            token = [SOS_token] + [lang.word2index[word.text] for word in spacy_en.tokenizer(sentence)]\n","            token = token[:max_len - 1]\n","            token.append(EOS_token)\n","\n","            while len(token) < max_len:\n","                token.append(PAD_TOKEN)\n","            token_out.append(token)\n","        return token_out\n","\n","    def __len__(self):\n","        return len(self.src)\n","\n","    def __getitem__(self, idx):\n","        items = {\"src\" : torch.tensor(self.src[idx]), \n","                 \"trg\" : torch.tensor(self.trg[idx])}\n","        return items\n","\n","news_dataset = News_Dataset(df['text'].tolist(), df['headlines'].tolist(), src_lang, trg_lang)\n","train_dataset, test_dataset = torch.utils.data.random_split(news_dataset, [len(news_dataset) - 20000, 20000])\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"],"metadata":{"id":"ur9sbDzQwy7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### modeling\n","\n","class Encoder(torch.nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        # initializations\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.embedding = torch.nn.Embedding(input_dim, emb_dim)\n","\n","        # if batch_first=True, output = (batch, seq, feature) instead of (seq, batch, feature).\n","        # cell and hidden remain as (seq, batch, feature)\n","        self.rnn = torch.nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, \n","                                 batch_first=True, bidirectional=False)\n","        self.dropout = torch.nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        # src = [batch size, src len]\n","        # embedded = [batch size, src len, emb dim]\n","        embedded = self.embedding(src)\n","        embedded = self.dropout(embedded)\n","        \n","        # outputs = [batch size, src len, hid dim * n directions]\n","        # hidden = [n layers * n directions, batch size, hid dim]\n","        # cell = [n layers * n directions, batch size, hid dim]\n","        # outputs are always from the top hidden layer\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        return hidden, cell\n"," \n","class Decoder(torch.nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        # initialize\n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.embedding = torch.nn.Embedding(output_dim, emb_dim)\n","\n","        # for decoder we will use n_directions 1\n","        self.rnn = torch.nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout, \n","                                 batch_first=True, bidirectional=False)\n","        # fully connected layer to predict words\n","        self.fc_out = torch.nn.Linear(hid_dim, output_dim)\n","        self.dropout = torch.nn.Dropout(dropout)\n","        \n","    def forward(self, trg, hidden, cell):\n","\n","        # trg = [batch size, 1]\n","        trg = trg.unsqueeze(1)\n","\n","        #embedded = [batch size, 1, emb dim]\n","        embedded = self.dropout(self.embedding(trg))\n","\n","        # seq len and n directions will always be 1 in the decoder\n","        # output = [batch size, 1, hid dim * n directions]\n","        # hidden = [batch size, n layers * n directions, hid dim]\n","        # cell = [batch size, n layers * n directions, hid dim]\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        \n","        # prediction = [batch size, output dim]\n","        prediction = self.fc_out(output.squeeze(1))\n","        return prediction, hidden, cell\n","\n","class Seq2Seq(torch.nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        \n","        # teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","\n","        # src = [batch size, src len] where src_len is number of tokens in source sentence\n","        # trg = [batch size, trg len]\n","        batch_size = trg.shape[0]\n","        trg_len = trg.shape[1]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        # tensor to store decoder outputs\n","        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n","        \n","        # last hidden state of the encoder is used as the initial hidden state of the decoder\n","        hidden, cell = self.encoder(src)\n","        \n","        # first input to the decoder is the <sos> tokens\n","        dec_input = trg[:, 0]\n","\n","        for t in range(1, trg_len):\n","            \n","            # insert input token embedding, previous hidden and previous cell states\n","            # receive output tensor (predictions) and new hidden and cell states\n","\n","            output, hidden, cell = self.decoder(dec_input, hidden, cell)\n","            # place predictions in a tensor holding predictions for each token\n","            outputs[:, t, :] = output\n","            \n","            # decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            # get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            # if teacher forcing, use actual next token as next input\n","            # if not, use predicted token\n","            dec_input = trg[:, t] if teacher_force else top1\n","        \n","        return outputs"],"metadata":{"id":"y_SXbuklvhSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seq2seq model's config variables\n","INPUT_DIM = src_lang.n_words\n","OUTPUT_DIM = trg_lang.n_words\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","HID_DIM = 256\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.1\n","DEC_DROPOUT = 0.1\n","\n","# initialize seq2seq model\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","model = Seq2Seq(enc, dec, 'cuda')"],"metadata":{"id":"M7jL95qr82T5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### testing\n","for batch in train_loader:\n","    break\n","\n","hidden, cell = enc.forward(batch['src'])\n","print('Encoder Output:', hidden.size(), cell.size())\n","\n","dec_input = batch['trg'][:, 0]\n","print('Decoder Input', dec_input.shape)\n","output, hidden, cell = dec(dec_input, hidden, cell)\n","print('Decoder Output:', output.size(), cell.size())\n","print('Decoder Output First Letter: ', output.argmax(1))\n","\n","final_output = model(batch['src'], batch['trg'])\n","print('Final Output:', final_output.size())\n","\n","# loop from 0 to 32\n","outputs = torch.zeros(batch['trg'].size(0), 32, 41147)\n","outputs[:, 0, :] = output\n","teacher_force = random.random() < 0.8\n","dec_input = batch['trg'][:, 1] if teacher_force else output.argmax(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S14vT3mr9PiU","executionInfo":{"status":"ok","timestamp":1658216533999,"user_tz":-480,"elapsed":4421,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"2551de35-891b-4ff8-e424-829efd5e09b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder Output: torch.Size([2, 32, 256]) torch.Size([2, 32, 256])\n","Decoder Input torch.Size([32])\n","Decoder Output: torch.Size([32, 41147]) torch.Size([2, 32, 256])\n","Decoder Output First Letter:  tensor([36728, 36728, 36728, 25453, 14006, 36728, 36728, 36433, 36728, 36728,\n","        36728, 36728, 36433, 36728, 36728, 36728, 36728, 36728, 36728, 36728,\n","        36728, 36728, 36728, 10167, 36728, 36728, 36433, 36728, 36728, 36728,\n","         8761, 36728])\n","Final Output: torch.Size([32, 32, 41147])\n"]}]},{"cell_type":"code","source":["### trainer\n","\n","class Seq2Seq_trainer(object):\n","    def __init__(self, model, train_iterator, valid_iterator, pad_index, device, clip, learning_rate):\n","        # initialize config variables\n","        self.model = model.to(device)\n","        self.train_iterator = train_iterator\n","        self.valid_iterator = valid_iterator\n","        self.clip = clip\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n","        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_index)\n","        self.model.apply(self.init_weights)\n","        self.device = device\n","        print(f'The model has {self.count_parameters(self.model):,} trainable parameters')\n","    \n","    def init_weights(self,m):\n","        for name, param in m.named_parameters():\n","            torch.nn.init.uniform_(param.data, -0.08, 0.08)\n","        \n","    def count_parameters(self, model):\n","        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    def train(self):\n","        self.model.train()\n","        epoch_loss = 0\n","\n","        for i, batch in enumerate(self.train_iterator):\n","            \n","            # trg = [batch size, trg len]\n","            src = batch['src'].to(self.device)\n","            trg = batch['trg'].to(self.device)\n","            self.optimizer.zero_grad()\n","\n","            # output = [batch size, trg len, output dim]\n","            output = self.model(src, trg)\n","            \n","            # batch size * seq_len for criterion (cross_ent only allow (N, H))\n","            # trg = [(trg len - 1) * batch size]\n","            # output = [(trg len - 1) * batch size, output dim]\n","            output = output[:, 1:, :].reshape(-1, output.shape[-1])\n","            trg = trg[:, 1:].reshape(-1)\n","            # loss function\n","            loss = self.criterion(output, trg)\n","            loss.backward()\n","            \n","\n","            # clip to prevent exploding\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n","            self.optimizer.step()\n","            epoch_loss += loss.item()\n","        return epoch_loss / len(self.train_iterator)\n","    \n","    def evaluate(self):\n","        self.model.eval()\n","        epoch_loss = 0\n","        with torch.no_grad():\n","            for i, batch in enumerate(self.valid_iterator):\n","\n","                # trg = [batch size, trg len]\n","                # output = [batch size, trg len, output dim]\n","                src = batch['src'].to(self.device)\n","                trg = batch['trg'].to(self.device)\n","                output = self.model(src, trg, 0) # turn off teacher forcing\n","\n","                output = output[:, 1:, :].reshape(-1, output.shape[-1])\n","                trg = trg[:, 1:].reshape(-1)\n","\n","                loss = self.criterion(output, trg)\n","                epoch_loss += loss.item()\n","        return epoch_loss / len(self.valid_iterator)\n","    \n","    def epoch_time(self, start_time, end_time):\n","        elapsed_time = end_time - start_time\n","        elapsed_mins = int(elapsed_time / 60)\n","        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","        return elapsed_mins, elapsed_secs\n","    \n","    def fit(self, nepochs):\n","        best_valid_loss = float('inf')\n","\n","        for epoch in tqdm(range(nepochs)):\n","            start_time = time.time()\n","            train_loss = self.train()\n","            valid_loss = self.evaluate()\n","            end_time = time.time()\n","            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n","\n","            if valid_loss < best_valid_loss:\n","                best_valid_loss = valid_loss\n","                # torch.save(model.state_dict(), 'tut1-model.pt')\n","                print(f'Epoch with best validation loss: {epoch + 1:02}')\n","\n","            print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","            print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss) : 7.3f}')\n","            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss) : 7.3f}')\n","\n","    def predict(self, iterator):\n","        self.model.eval()\n","        with torch.no_grad():\n","\n","            for i, batch in enumerate(tqdm(iterator)):\n","                src = batch['src'].to(self.device)\n","                trg = batch['trg'].to(self.device)\n","                # turn off teacher forcing\n","                output = self.model(src, trg, 0) \n","                \n","                if i == 0:\n","                    outputs = torch.argmax(output, -1)    \n","                else:\n","                    outputs = torch.cat((outputs, torch.argmax(output, -1)), 0)\n","\n","        # outputs = [len(iterator), trg_len]\n","        return outputs"],"metadata":{"id":"NyMfn5OcLmME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seq2seq model's config variables\n","INPUT_DIM = src_lang.n_words\n","OUTPUT_DIM = trg_lang.n_words\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","HID_DIM = 256\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.1\n","DEC_DROPOUT = 0.1\n","\n","# initialize seq2seq model\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","model = Seq2Seq(enc, dec, 'cuda')\n","\n","# define data loader\n","train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n","\n","trainer = Seq2Seq_trainer(model, train_loader, test_loader, 0, 'cuda', 1, 1e-3)\n","trainer.fit(10)\n","result = trainer.predict(test_loader).to('cpu').numpy()\n","print(\" \".join([trg_lang.index2word.get(x) for x in result[99]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzfbYhgUPgPt","outputId":"2250fcfd-e88d-4a4a-bd72-b4a4e24eb52b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 30,475,067 trainable parameters\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]}]}]}