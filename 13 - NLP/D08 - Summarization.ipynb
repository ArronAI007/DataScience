{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers nltk"],"metadata":{"id":"uUebGKfIkvnw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","from nltk.corpus import stopwords\n","import nltk\n","import random\n","import math\n","import time\n","import torch\n","import torch.nn.functional as F\n","import spacy\n","from tqdm import tqdm\n","spacy_en = spacy.load('en_core_web_sm')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8_P-cucOOWu","executionInfo":{"status":"ok","timestamp":1669818072792,"user_tz":-480,"elapsed":19448,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"a5f4dd7d-a71c-425d-a54d-7994c5446f32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# 1) LSTM (Encoder + Decoder)"],"metadata":{"id":"V-JdFuRYCk1n"}},{"cell_type":"code","source":["stop_words = stopwords.words('english')\n","\n","def preprocess(text):\n","    text = text.lower() # lowercase\n","    text = text.split()\n","    for i in range(len(text)):\n","        word = text[i]\n","    text = \" \".join(text)\n","    text = text.split()\n","    newtext = []\n","    for word in text:\n","        if word not in stop_words:\n","            newtext.append(word)\n","    text = \" \".join(newtext)\n","    text = text.replace(\"'s\",'')\n","    text = re.sub(r'\\(.*\\)','',text)\n","    text = re.sub(r'[^a-zA-Z0-9. ]','',text)\n","    text = re.sub(r'\\.',' . ',text)\n","    return text\n","\n","df = pd.read_csv(\n","    \"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\",\n","    encoding='utf-8'\n",")\n","df['headlines'] = df['headlines'].apply(lambda x:preprocess(x))\n","df['text'] = df['text'].apply(lambda x:preprocess(x))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ptYr6JkxcXaC","executionInfo":{"status":"ok","timestamp":1669812407114,"user_tz":-480,"elapsed":23824,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"a16ac021-128d-462b-c824-c6dc48105ef4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           headlines  \\\n","0  upgrad learner switches career ml  al 90 salar...   \n","1   delhi techie wins free food swiggy one year cred   \n","2  new zealand end rohit sharmaled india 12match ...   \n","3  aegon life iterm insurance plan helps customer...   \n","4           known hirani yrs metoo claims true sonam   \n","\n","                                                text  \n","0  saurav kant alumnus upgrad iiitb pg program ma...  \n","1  kunal shah credit card bill payment platform c...  \n","2  new zealand defeated india 8 wickets fourth od...  \n","3  aegon life iterm insurance plan customers enjo...  \n","4  speaking sexual harassment allegations rajkuma...  "],"text/html":["\n","  <div id=\"df-2aa157d2-666f-4afa-b9be-71772f186b7a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>upgrad learner switches career ml  al 90 salar...</td>\n","      <td>saurav kant alumnus upgrad iiitb pg program ma...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>delhi techie wins free food swiggy one year cred</td>\n","      <td>kunal shah credit card bill payment platform c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>new zealand end rohit sharmaled india 12match ...</td>\n","      <td>new zealand defeated india 8 wickets fourth od...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>aegon life iterm insurance plan helps customer...</td>\n","      <td>aegon life iterm insurance plan customers enjo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>known hirani yrs metoo claims true sonam</td>\n","      <td>speaking sexual harassment allegations rajkuma...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2aa157d2-666f-4afa-b9be-71772f186b7a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2aa157d2-666f-4afa-b9be-71772f186b7a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2aa157d2-666f-4afa-b9be-71772f186b7a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["### create vocab index\n","\n","# start and end of sentence\n","SOS_token = 100\n","EOS_token = 101\n","PAD_TOKEN = 0\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {SOS_token: \"SOS\", EOS_token: \"EOS\", PAD_TOKEN: \"PAD\"}\n","        self.n_words = 3  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in spacy_en.tokenizer(sentence):\n","            self.addWord(word.text)\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","trg_lang = Lang(df['headlines'])\n","src_lang = Lang(df['text'])\n","\n","for line in df['headlines'].tolist():\n","    trg_lang.addSentence(line)\n","\n","for line in df['text'].tolist():\n","    src_lang.addSentence(line)\n","\n","print(trg_lang.n_words)\n","print(src_lang.n_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kw_GQV0v9uc","executionInfo":{"status":"ok","timestamp":1658216514033,"user_tz":-480,"elapsed":22809,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"e68f9829-15c6-4bac-9803-4764e75b56e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["41147\n","99924\n"]}]},{"cell_type":"code","source":["### dataset\n","\n","from torch.utils.data import DataLoader, Dataset, random_split\n","\n","class News_Dataset(Dataset):\n","    def __init__(self, src, trg, src_lang, trg_lang, max_len=256):\n","        self.max_len = max_len\n","        self.src = self.tokenize(src, src_lang, 128)\n","        self.trg = self.tokenize(trg, trg_lang, 32)\n","\n","    def tokenize(self, sentence_list, lang, max_len):\n","        token_out = []\n","        for sentence in sentence_list:\n","            token = [SOS_token] + [lang.word2index[word.text] for word in spacy_en.tokenizer(sentence)]\n","            token = token[:max_len - 1]\n","            token.append(EOS_token)\n","\n","            while len(token) < max_len:\n","                token.append(PAD_TOKEN)\n","            token_out.append(token)\n","        return token_out\n","\n","    def __len__(self):\n","        return len(self.src)\n","\n","    def __getitem__(self, idx):\n","        items = {\"src\" : torch.tensor(self.src[idx]),\n","                 \"trg\" : torch.tensor(self.trg[idx])}\n","        return items\n","\n","news_dataset = News_Dataset(df['text'].tolist(), df['headlines'].tolist(), src_lang, trg_lang)\n","train_dataset, test_dataset = torch.utils.data.random_split(news_dataset, [len(news_dataset) - 20000, 20000])\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"],"metadata":{"id":"ur9sbDzQwy7z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### modeling\n","\n","class Encoder(torch.nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","\n","        # initializations\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.embedding = torch.nn.Embedding(input_dim, emb_dim)\n","\n","        # if batch_first=True, output = (batch, seq, feature) instead of (seq, batch, feature).\n","        # cell and hidden remain as (seq, batch, feature)\n","        self.rnn = torch.nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout,\n","                                 batch_first=True, bidirectional=False)\n","        self.dropout = torch.nn.Dropout(dropout)\n","\n","    def forward(self, src):\n","        # src = [batch size, src len]\n","        # embedded = [batch size, src len, emb dim]\n","        embedded = self.embedding(src)\n","        embedded = self.dropout(embedded)\n","\n","        # outputs = [batch size, src len, hid dim * n directions]\n","        # hidden = [n layers * n directions, batch size, hid dim]\n","        # cell = [n layers * n directions, batch size, hid dim]\n","        # outputs are always from the top hidden layer\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        return hidden, cell\n","\n","class Decoder(torch.nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","\n","        # initialize\n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.embedding = torch.nn.Embedding(output_dim, emb_dim)\n","\n","        # for decoder we will use n_directions 1\n","        self.rnn = torch.nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout,\n","                                 batch_first=True, bidirectional=False)\n","        # fully connected layer to predict words\n","        self.fc_out = torch.nn.Linear(hid_dim, output_dim)\n","        self.dropout = torch.nn.Dropout(dropout)\n","\n","    def forward(self, trg, hidden, cell):\n","\n","        # trg = [batch size, 1]\n","        trg = trg.unsqueeze(1)\n","\n","        #embedded = [batch size, 1, emb dim]\n","        embedded = self.dropout(self.embedding(trg))\n","\n","        # seq len and n directions will always be 1 in the decoder\n","        # output = [batch size, 1, hid dim * n directions]\n","        # hidden = [batch size, n layers * n directions, hid dim]\n","        # cell = [batch size, n layers * n directions, hid dim]\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","\n","        # prediction = [batch size, output dim]\n","        prediction = self.fc_out(output.squeeze(1))\n","        return prediction, hidden, cell\n","\n","class Seq2Seq(torch.nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","        assert encoder.hid_dim == decoder.hid_dim, \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \"Encoder and decoder must have equal number of layers!\"\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","\n","        # teacher_forcing_ratio is probability to use teacher forcing\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","\n","        # src = [batch size, src len] where src_len is number of tokens in source sentence\n","        # trg = [batch size, trg len]\n","        batch_size = trg.shape[0]\n","        trg_len = trg.shape[1]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        # tensor to store decoder outputs\n","        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n","\n","        # last hidden state of the encoder is used as the initial hidden state of the decoder\n","        hidden, cell = self.encoder(src)\n","\n","        # first input to the decoder is the <sos> tokens\n","        dec_input = trg[:, 0]\n","\n","        for t in range(1, trg_len):\n","\n","            # insert input token embedding, previous hidden and previous cell states\n","            # receive output tensor (predictions) and new hidden and cell states\n","\n","            output, hidden, cell = self.decoder(dec_input, hidden, cell)\n","            # place predictions in a tensor holding predictions for each token\n","            outputs[:, t, :] = output\n","\n","            # decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","\n","            # get the highest predicted token from our predictions\n","            top1 = output.argmax(1)\n","\n","            # if teacher forcing, use actual next token as next input\n","            # if not, use predicted token\n","            dec_input = trg[:, t] if teacher_force else top1\n","\n","        return outputs"],"metadata":{"id":"y_SXbuklvhSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seq2seq model's config variables\n","INPUT_DIM = src_lang.n_words\n","OUTPUT_DIM = trg_lang.n_words\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","HID_DIM = 256\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.1\n","DEC_DROPOUT = 0.1\n","\n","# initialize seq2seq model\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","model = Seq2Seq(enc, dec, 'cuda')"],"metadata":{"id":"M7jL95qr82T5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### testing\n","for batch in train_loader:\n","    break\n","\n","hidden, cell = enc.forward(batch['src'])\n","print('Encoder Output:', hidden.size(), cell.size())\n","\n","dec_input = batch['trg'][:, 0]\n","print('Decoder Input', dec_input.shape)\n","output, hidden, cell = dec(dec_input, hidden, cell)\n","print('Decoder Output:', output.size(), cell.size())\n","print('Decoder Output First Letter: ', output.argmax(1))\n","\n","final_output = model(batch['src'], batch['trg'])\n","print('Final Output:', final_output.size())\n","\n","# loop from 0 to 32\n","outputs = torch.zeros(batch['trg'].size(0), 32, 41147)\n","outputs[:, 0, :] = output\n","teacher_force = random.random() < 0.8\n","dec_input = batch['trg'][:, 1] if teacher_force else output.argmax(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S14vT3mr9PiU","executionInfo":{"status":"ok","timestamp":1658216533999,"user_tz":-480,"elapsed":4421,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"2551de35-891b-4ff8-e424-829efd5e09b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder Output: torch.Size([2, 32, 256]) torch.Size([2, 32, 256])\n","Decoder Input torch.Size([32])\n","Decoder Output: torch.Size([32, 41147]) torch.Size([2, 32, 256])\n","Decoder Output First Letter:  tensor([36728, 36728, 36728, 25453, 14006, 36728, 36728, 36433, 36728, 36728,\n","        36728, 36728, 36433, 36728, 36728, 36728, 36728, 36728, 36728, 36728,\n","        36728, 36728, 36728, 10167, 36728, 36728, 36433, 36728, 36728, 36728,\n","         8761, 36728])\n","Final Output: torch.Size([32, 32, 41147])\n"]}]},{"cell_type":"code","source":["### trainer\n","\n","class Seq2Seq_trainer(object):\n","    def __init__(self, model, train_iterator, valid_iterator, pad_index, device, clip, learning_rate):\n","        # initialize config variables\n","        self.model = model.to(device)\n","        self.train_iterator = train_iterator\n","        self.valid_iterator = valid_iterator\n","        self.clip = clip\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n","        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_index)\n","        self.model.apply(self.init_weights)\n","        self.device = device\n","        print(f'The model has {self.count_parameters(self.model):,} trainable parameters')\n","\n","    def init_weights(self,m):\n","        for name, param in m.named_parameters():\n","            torch.nn.init.uniform_(param.data, -0.08, 0.08)\n","\n","    def count_parameters(self, model):\n","        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","    def train(self):\n","        self.model.train()\n","        epoch_loss = 0\n","\n","        for i, batch in enumerate(self.train_iterator):\n","\n","            # trg = [batch size, trg len]\n","            src = batch['src'].to(self.device)\n","            trg = batch['trg'].to(self.device)\n","            self.optimizer.zero_grad()\n","\n","            # output = [batch size, trg len, output dim]\n","            output = self.model(src, trg)\n","\n","            # batch size * seq_len for criterion (cross_ent only allow (N, H))\n","            # trg = [(trg len - 1) * batch size]\n","            # output = [(trg len - 1) * batch size, output dim]\n","            output = output[:, 1:, :].reshape(-1, output.shape[-1])\n","            trg = trg[:, 1:].reshape(-1)\n","            # loss function\n","            loss = self.criterion(output, trg)\n","            loss.backward()\n","\n","            # clip to prevent exploding\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n","            self.optimizer.step()\n","            epoch_loss += loss.item()\n","        return epoch_loss / len(self.train_iterator)\n","\n","    def evaluate(self):\n","        self.model.eval()\n","        epoch_loss = 0\n","        with torch.no_grad():\n","            for i, batch in enumerate(self.valid_iterator):\n","\n","                # trg = [batch size, trg len]\n","                # output = [batch size, trg len, output dim]\n","                src = batch['src'].to(self.device)\n","                trg = batch['trg'].to(self.device)\n","                output = self.model(src, trg, 0) # turn off teacher forcing\n","\n","                output = output[:, 1:, :].reshape(-1, output.shape[-1])\n","                trg = trg[:, 1:].reshape(-1)\n","\n","                loss = self.criterion(output, trg)\n","                epoch_loss += loss.item()\n","        return epoch_loss / len(self.valid_iterator)\n","\n","    def epoch_time(self, start_time, end_time):\n","        elapsed_time = end_time - start_time\n","        elapsed_mins = int(elapsed_time / 60)\n","        elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","        return elapsed_mins, elapsed_secs\n","\n","    def fit(self, nepochs):\n","        best_valid_loss = float('inf')\n","\n","        for epoch in tqdm(range(nepochs)):\n","            start_time = time.time()\n","            train_loss = self.train()\n","            valid_loss = self.evaluate()\n","            end_time = time.time()\n","            epoch_mins, epoch_secs = self.epoch_time(start_time, end_time)\n","\n","            if valid_loss < best_valid_loss:\n","                best_valid_loss = valid_loss\n","                # torch.save(model.state_dict(), 'tut1-model.pt')\n","                print(f'Epoch with best validation loss: {epoch + 1:02}')\n","\n","            print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","            print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss) : 7.3f}')\n","            print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss) : 7.3f}')\n","\n","    def predict(self, iterator):\n","        self.model.eval()\n","        with torch.no_grad():\n","\n","            for i, batch in enumerate(tqdm(iterator)):\n","                src = batch['src'].to(self.device)\n","                trg = batch['trg'].to(self.device)\n","                # turn off teacher forcing\n","                output = self.model(src, trg, 0)\n","\n","                if i == 0:\n","                    outputs = torch.argmax(output, -1)\n","                else:\n","                    outputs = torch.cat((outputs, torch.argmax(output, -1)), 0)\n","\n","        # outputs = [len(iterator), trg_len]\n","        return outputs"],"metadata":{"id":"NyMfn5OcLmME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seq2seq model's config variables\n","INPUT_DIM = src_lang.n_words\n","OUTPUT_DIM = trg_lang.n_words\n","ENC_EMB_DIM = 128\n","DEC_EMB_DIM = 128\n","HID_DIM = 256\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.1\n","DEC_DROPOUT = 0.1\n","\n","# initialize seq2seq model\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","model = Seq2Seq(enc, dec, 'cuda')\n","\n","# define data loader\n","train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)\n","\n","trainer = Seq2Seq_trainer(model, train_loader, test_loader, 0, 'cuda', 1, 1e-3)\n","trainer.fit(10)\n","result = trainer.predict(test_loader).to('cpu').numpy()\n","print(\" \".join([trg_lang.index2word.get(x) for x in result[99]]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SzfbYhgUPgPt","outputId":"2250fcfd-e88d-4a4a-bd72-b4a4e24eb52b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 30,475,067 trainable parameters\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]}]},{"cell_type":"markdown","source":["# 2) Abstractive Summaization"],"metadata":{"id":"CxvA8aS2-L24"}},{"cell_type":"code","source":["from transformers import BartForConditionalGeneration, BartTokenizer, BartConfig\n","\n","tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n","model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n","df = pd.read_csv(\n","    \"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\",\n","    encoding='utf-8'\n",")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"bBfKGmjo-Ria","executionInfo":{"status":"ok","timestamp":1669812967583,"user_tz":-480,"elapsed":9611,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"8da68c31-fa7e-4b96-a470-825e68005ab6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           headlines  \\\n","0  upGrad learner switches to career in ML & Al w...   \n","1  Delhi techie wins free food from Swiggy for on...   \n","2  New Zealand end Rohit Sharma-led India's 12-ma...   \n","3  Aegon life iTerm insurance plan helps customer...   \n","4  Have known Hirani for yrs, what if MeToo claim...   \n","\n","                                                text  \n","0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n","1  Kunal Shah's credit card bill payment platform...  \n","2  New Zealand defeated India by 8 wickets in the...  \n","3  With Aegon Life iTerm Insurance plan, customer...  \n","4  Speaking about the sexual harassment allegatio...  "],"text/html":["\n","  <div id=\"df-10ede2e8-1276-4291-9615-a2a8ca19296a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n","      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Delhi techie wins free food from Swiggy for on...</td>\n","      <td>Kunal Shah's credit card bill payment platform...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n","      <td>New Zealand defeated India by 8 wickets in the...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Aegon life iTerm insurance plan helps customer...</td>\n","      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n","      <td>Speaking about the sexual harassment allegatio...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10ede2e8-1276-4291-9615-a2a8ca19296a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-10ede2e8-1276-4291-9615-a2a8ca19296a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-10ede2e8-1276-4291-9615-a2a8ca19296a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["test_str = df['text'].values[2:3].tolist()\n","inputs = tokenizer.batch_encode_plus(test_str, return_tensors='pt', padding=True)\n","\n","summary_ids = model.generate(\n","    inputs['input_ids'],\n","    early_stopping=False,\n","    repetition_penalty=1.4,\n","    length_penalty=1,\n","    min_length=20,\n","    max_length=100,\n",")\n","\n","bart_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","print('Original Text', test_str)\n","print('Summary',bart_summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iz9NLWlSmytC","executionInfo":{"status":"ok","timestamp":1669813357024,"user_tz":-480,"elapsed":13494,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"84dbe4fd-3a8c-47f2-a4fa-6fb30371eddc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original Text [\"New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\"]\n","Summary New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n"]}]},{"cell_type":"markdown","source":["# 3) Extractive Summary"],"metadata":{"id":"5TOiPz-z6Szz"}},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import numpy as np\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.cluster.util import cosine_distance\n","\n","df = pd.read_csv(\n","    \"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\",\n","    encoding='utf-8'\n",")\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"A_b9ug-NBaCz","executionInfo":{"status":"ok","timestamp":1669819904683,"user_tz":-480,"elapsed":1737,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"e70843a1-12c8-4057-a40c-ed734f9cab19"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           headlines  \\\n","0  upGrad learner switches to career in ML & Al w...   \n","1  Delhi techie wins free food from Swiggy for on...   \n","2  New Zealand end Rohit Sharma-led India's 12-ma...   \n","3  Aegon life iTerm insurance plan helps customer...   \n","4  Have known Hirani for yrs, what if MeToo claim...   \n","\n","                                                text  \n","0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n","1  Kunal Shah's credit card bill payment platform...  \n","2  New Zealand defeated India by 8 wickets in the...  \n","3  With Aegon Life iTerm Insurance plan, customer...  \n","4  Speaking about the sexual harassment allegatio...  "],"text/html":["\n","  <div id=\"df-ff695114-e4a5-4fe1-a2c3-54b5f492f9fd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headlines</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n","      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Delhi techie wins free food from Swiggy for on...</td>\n","      <td>Kunal Shah's credit card bill payment platform...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n","      <td>New Zealand defeated India by 8 wickets in the...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Aegon life iTerm insurance plan helps customer...</td>\n","      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n","      <td>Speaking about the sexual harassment allegatio...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff695114-e4a5-4fe1-a2c3-54b5f492f9fd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ff695114-e4a5-4fe1-a2c3-54b5f492f9fd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ff695114-e4a5-4fe1-a2c3-54b5f492f9fd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def split_sentence(text):\n","    text_list = text.split(\". \")\n","    sentences = []\n","    for sentence in text_list:\n","        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n","    sentences.pop()\n","    return sentences\n","\n","def sentence_similarity(sent1, sent2, stopwords=None):\n","    if stopwords is None:\n","        stopwords = []\n","\n","    sent1 = [w.lower() for w in sent1]\n","    sent2 = [w.lower() for w in sent2]\n","    all_words = list(set(sent1 + sent2))\n","    vector1 = [0] * len(all_words)\n","    vector2 = [0] * len(all_words)\n","\n","    # Build the vector for the first sentence\n","    # if word present then add 1 to vector indice, if stopword then skip\n","    for w in sent1:\n","        if w in stopwords:\n","            continue\n","        vector1[all_words.index(w)] += 1\n","\n","    for w in sent2:\n","        if w in stopwords:\n","            continue\n","        vector2[all_words.index(w)] += 1\n","\n","    return 1 - cosine_distance(vector1, vector2)\n","\n","def build_similarity_matrix(sentences, stop_words):\n","\n","    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n","\n","    # Get similarity score for pairs of sentences at idx1 and idx2\n","    for idx1 in range(len(sentences)):\n","        for idx2 in range(len(sentences)):\n","            if idx1 == idx2:\n","                continue\n","            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n","\n","    return similarity_matrix\n","\n","stop_words = stopwords.words('english')"],"metadata":{"id":"MWmXjMku8v2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### n sample set and combine\n","sample_text = df['text'].sample(10).values.tolist()\n","sample_text = [re.sub(\"[.]\", \"\", x) for x in sample_text]\n","combined_text = '. '.join(sample_text)\n","splitted_text = split_sentence(combined_text)\n","print(sentence_similarity(splitted_text[0], splitted_text[1], stop_words))\n","\n","### get similarity matrix for each sentences\n","sentence_similarity_martix = build_similarity_matrix(splitted_text, stop_words)\n","scores_df = pd.DataFrame(sentence_similarity_martix)\n","scores_df = scores_df.sum().to_frame().reset_index(drop=True).sort_values(0, ascending=False)\n","scores = scores_df[0].to_dict()\n","\n","### sort sentences according to similarity score\n","ranked_sentence = sorted(\n","    ((scores[i], s) for i, s in enumerate(splitted_text)),\n","    reverse=True\n",")\n","\n","### extract the actual sentences\n","ranked_sentences_df = pd.DataFrame(ranked_sentence, columns=['similarity_score', 'content'])\n","ranked_sentences_df['content'] = [' '.join(x) for x in ranked_sentences_df['content']]\n","\n","### select the top n most representative sentence\n","top_n = 5\n","summarize_text = ranked_sentences_df.head(top_n)['content'].values.tolist()\n","summarize_text = \". \".join(summarize_text)\n","summarize_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"_7cAzvBoBgvv","executionInfo":{"status":"ok","timestamp":1669822977354,"user_tz":-480,"elapsed":314,"user":{"displayName":"Kean Chan","userId":"05792587367281359063"}},"outputId":"3a1bc6a8-43a6-4343-82b5-e024698fa93e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["'According to reports, Google is developing a technology that will let publishers create visual-oriented media content like Snapchat\\'s Discover feature Google\\'s new feature will be a mix of photos, videos, and text, the reports added Google is reportedly in talks with CNN, The Washington Post, Time, and Vox Media, among others regarding their participation in the feature . Actress Kajol, while speaking about pay parity in Bollywood, said, \"The pay should be according to genre, how the box office is and box office success\" \"Pay equality is coming up to par To call it a \\'trend\\' would be strange (as it is) something that should be a natural fact of life,\" she added. Chhattisgarh\\'s Bastar, which is among the worst Maoist-affected regions, got its first Business Process Outsourcing (BPO) centre run by a private firm Four hundred tribal youths will be employed, at a monthly stipend of â\\x82¹4,000, and will be trained in typing, speaking English and technology Located at a government college building, the centre is aimed at employing tribal youth. Around 25 lakh people were reported to have gathered at Delhi\\'s India Gate to celebrate the New Year on Monday, leading to a massive traffic jam Despite the deployment of more than 50 police personnel, the authorities had a difficult time managing the massive crowd In the evening, the traffic police also issued advisories asking people to take alternate routes. Following a phone call with Nelson Mandela in June 1990, former UK PM Margaret Thatcher had told her then-Foreign Affairs Adviser that the ex-South African President had \"a closed mind\", according to newly released secret files The UK\\'s then-Ambassador to South Africa, Sir Robin Renwick, had said Mandela wasn\\'t \"as intelligent\" as ex-Zimbabwe President Robert Mugabe, the files further revealed'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":52}]}]}